{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4FI7KjLGUR3ptljAznrcY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ5hLMQRYvbO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from scipy.stats import norm, gaussian_kde\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MISS_NUM = '12' # 12, 24, 36, 48\n",
        "DATA_NUM = '716' # 14, 366, 716"
      ],
      "metadata": {
        "id": "TGbpFGAhYxj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data = pd.read_csv(\"Data\"+DATA_NUM+\"_15min.csv\")\n",
        "num_day  = int(len(Data)/96)\n",
        "num_time = 96\n",
        "data = np.reshape(np.array(Data['0']), (num_day,num_time))/np.max(Data['0'])"
      ],
      "metadata": {
        "id": "gK4y4ieYYzzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range1 = [6*x-6 for x in range(1,62)]\n",
        "range2 = [6*x-5 for x in range(1,62)]\n",
        "range3 = [6*x-4 for x in range(1,62)]\n",
        "range4 = [6*x-3 for x in range(1,62)]\n",
        "range5 = [6*x-2 for x in range(1,62)]\n",
        "range6 = [6*x-1 for x in range(1,62)]\n",
        "\n",
        "range_train = range1 + range2 + range3 + range4\n",
        "range_val   = range5\n",
        "range_test  = range6\n",
        "\n",
        "l  = int(MISS_NUM)\n",
        "l2 = int(l/2)\n",
        "\n",
        "mean_corrector_train = 96/l2\n",
        "mean_corrector_val  = 96/l2\n",
        "mean_corrector_test  = 96/l\n",
        "\n",
        "try:\n",
        "    data_miss = np.array(pd.read_csv(\"DATA\"+DATA_NUM+\"_MISS\"+MISS_NUM+\".csv\", index_col=0))\n",
        "except:\n",
        "    data_miss = data.copy()\n",
        "    for i in range(num_day):\n",
        "        if i in range_test:\n",
        "            s = np.random.choice(range(1, 96-l))\n",
        "            data_miss[i][s:s+l] = 0\n",
        "        else:\n",
        "            s = np.random.choice(range(1, 96-l2))\n",
        "            data_miss[i][s:s+l2] = 0\n",
        "\n",
        "    pd.DataFrame(data_miss).to_csv(\"DATA\"+DATA_NUM+\"_MISS\"+MISS_NUM+\".csv\")"
      ],
      "metadata": {
        "id": "lh2rQ7uIMAMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_miss  = np.zeros((1,96))\n",
        "data_train_miss2 = np.zeros((1,96))\n",
        "data_val_miss    = np.zeros((1,96))\n",
        "data_val_miss2   = np.zeros((1,96))\n",
        "for i in range(len(data_miss)):\n",
        "    j = np.where(data_miss[i]==0)[0][0]\n",
        "    k = np.where(data_miss[i]==0)[0][-1]\n",
        "\n",
        "    if j > l2:\n",
        "        data_miss_sample = data_miss[i:i+1].copy()\n",
        "        data_miss_sample[0][j-l2:j] = 0\n",
        "        if i in range_train:\n",
        "            data_train_miss  = np.append(data_train_miss, data_miss[i:i+1], axis=0)\n",
        "            data_train_miss2 = np.append(data_train_miss2, data_miss_sample, axis=0)\n",
        "        if i in range_val:\n",
        "            data_val_miss  = np.append(data_val_miss, data_miss[i:i+1], axis=0)\n",
        "            data_val_miss2 = np.append(data_val_miss2, data_miss_sample, axis=0)\n",
        "    if k < 95-l2:\n",
        "        data_miss_sample = data_miss[i:i+1].copy()\n",
        "        data_miss_sample[0][k+1:k+1+l2] = 0\n",
        "        if i in range_train:\n",
        "            data_train_miss  = np.append(data_train_miss, data_miss[i:i+1], axis=0)\n",
        "            data_train_miss2 = np.append(data_train_miss2, data_miss_sample, axis=0)\n",
        "        if i in range_val:\n",
        "            data_val_miss  = np.append(data_val_miss, data_miss[i:i+1], axis=0)\n",
        "            data_val_miss2 = np.append(data_val_miss2, data_miss_sample, axis=0)\n",
        "\n",
        "data_train_miss  = data_train_miss[1:]\n",
        "data_train_miss2 = data_train_miss2[1:]\n",
        "data_val_miss    = data_val_miss[1:]\n",
        "data_val_miss2   = data_val_miss2[1:]\n",
        "data_test        = data[range_test]\n",
        "data_test_miss   = data_miss[range_test]"
      ],
      "metadata": {
        "id": "crxU1bCcY0R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Historical Average\n",
        "\n",
        "data_test_HA = data_test_miss.copy()\n",
        "for i in range(len(data_test_HA)):\n",
        "    j = np.where(data_test_miss[i]==0)[0][0]\n",
        "    d1 = max(range_test[i % len(range_test)] - 1, 0)\n",
        "    d2 = min(range_test[i % len(range_test)] + 1, len(data)-1)\n",
        "    data_test_HA[i][j:j+l] = 0.5*(data[d1][j:j+l] + data[d2][j:j+l])\n",
        "data_test_HA[data_test_miss != 0] = 0\n",
        "\n",
        "mse_test = np.mean(np.square(data_test_HA - (data_test - data_test_miss)))*mean_corrector_test\n",
        "mae_test = np.mean(np.abs(data_test_HA - (data_test - data_test_miss)))*mean_corrector_test\n",
        "\n",
        "NRMSE_test = round(100*np.sqrt(mse_test),2)\n",
        "NMAE_test  = round(100*mae_test,2)\n",
        "\n",
        "print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii_hGpfTZkkf",
        "outputId": "e77c6144-cb1d-4749-c310-8d2c89335eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRMSE_test: 8.32%        NMAE_test: 6.01%         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Interpolation\n",
        "\n",
        "def LI(v_left, v_right):\n",
        "    x = np.array(range(1,l+1))\n",
        "    y = (v_right - v_left)*x/(l+1) + v_left\n",
        "    return y\n",
        "\n",
        "data_test_LI = data_test_miss.copy()\n",
        "for i in range(len(data_test_LI)):\n",
        "    j = np.where(data_test_miss[i]==0)[0][0]\n",
        "    j_left  = np.where(data_test_miss[i]==0)[0][0] - 1\n",
        "    j_right = np.where(data_test_miss[i]==0)[0][-1] + 1\n",
        "    v_left  = data_test_miss[i][j_left]\n",
        "    v_right = data_test_miss[i][j_right]\n",
        "    data_test_LI[i][j:j+l] = LI(v_left, v_right)\n",
        "data_test_LI[data_test_miss != 0] = 0\n",
        "\n",
        "mse_test = np.mean(np.square(data_test_LI - (data_test - data_test_miss)))*mean_corrector_test\n",
        "mae_test = np.mean(np.abs(data_test_LI - (data_test - data_test_miss)))*mean_corrector_test\n",
        "\n",
        "NRMSE_test = round(100*np.sqrt(mse_test),2)\n",
        "NMAE_test  = round(100*mae_test,2)\n",
        "\n",
        "print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZGtXW94Z8Be",
        "outputId": "c047acb1-4601-4b05-f7c4-75fefe53c6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRMSE_test: 3.58%        NMAE_test: 2.51%         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AE\n",
        "\n",
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE, self).__init__()\n",
        "        self.fc1 = nn.Linear(96, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 64)\n",
        "        self.fc4 = nn.Linear(64, 96)\n",
        "        self.activation = nn.Sigmoid() #nn.ReLU()\n",
        "\n",
        "    def forward_train(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        z = self.fc2(x)\n",
        "        y = self.activation(z)\n",
        "        y = self.fc3(y)\n",
        "        y = self.activation(y)\n",
        "        y = self.fc4(y)\n",
        "        return z, y\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        z = self.fc2(x)\n",
        "        y = self.activation(z)\n",
        "        y = self.fc3(y)\n",
        "        y = self.activation(y)\n",
        "        y = self.fc4(y)\n",
        "        return z, y\n",
        "\n",
        "class AED(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AED, self).__init__()\n",
        "        self.fc1 = nn.Linear(96, 64)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 64)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.fc4 = nn.Linear(64, 96)\n",
        "        self.activation = nn.Sigmoid() #nn.ReLU()\n",
        "\n",
        "    def forward_train(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout1(x)\n",
        "        z = self.fc2(x)\n",
        "        y = self.activation(z)\n",
        "        y = self.fc3(y)\n",
        "        y = self.activation(y)\n",
        "        y = self.dropout2(y)\n",
        "        y = self.fc4(y)\n",
        "        return z, y\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        z = self.fc2(x)\n",
        "        y = self.activation(z)\n",
        "        y = self.fc3(y)\n",
        "        y = self.activation(y)\n",
        "        y = self.fc4(y)\n",
        "        return z, y\n",
        "\n",
        "def train_AE(model, batch, optimizer):\n",
        "    x, y = batch[0], batch[1]\n",
        "    x_hat = model.forward_train(x)[1]\n",
        "\n",
        "    loss = nn.functional.mse_loss(x_hat, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def train_MAE(model, batch, optimizer):\n",
        "    x, y = batch[0], batch[1]\n",
        "    x_hat = model.forward_train(x)[1]\n",
        "    x_hat[y == 0] = 0\n",
        "\n",
        "    loss = nn.functional.mse_loss(x_hat, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "lf0yjg_OaBe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoising AutoEncoder (Training)\n",
        "\n",
        "batch_size1 = 128\n",
        "total_batch1 = int(len(data_train_miss)/batch_size1) + 1\n",
        "batch_size2 = 32\n",
        "total_batch2 = int(len(data_val_miss)/batch_size2) + 1\n",
        "\n",
        "dae = AED()\n",
        "optimizer = optim.Adam(dae.parameters(), lr = 0.001)\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "for epoch in range(10000):\n",
        "    for i in range(total_batch1):\n",
        "        batch_x = torch.tensor(data_train_miss2[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch_y = torch.tensor(data_train_miss[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch = [batch_x, batch_y]\n",
        "        train_AE(dae, batch, optimizer)\n",
        "\n",
        "    data_train_DAE = dae.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_val_DAE   = dae.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_test_DAE  = dae.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "    data_train_DAE[data_train_miss - data_train_miss2 == 0] = 0\n",
        "    data_val_DAE[data_val_miss - data_val_miss2 == 0] = 0\n",
        "    data_test_DAE[data_test_miss != 0] = 0\n",
        "\n",
        "    mse_train += [np.mean(np.square(data_train_DAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mae_train += [np.mean(np.abs(data_train_DAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mse_val += [np.mean(np.square(data_val_DAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mae_val += [np.mean(np.abs(data_val_DAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mse_test += [np.mean(np.square(data_test_DAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "    mae_test += [np.mean(np.abs(data_test_DAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "    NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "    NMAE_train  = round(100*mae_train[-1],2)\n",
        "    NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "    NMAE_val  = round(100*mae_val[-1],2)\n",
        "    NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "    NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "    if mse_val[-1] == np.min(mse_val):\n",
        "        torch.save(dae.state_dict(), 'DAE_'+DATA_NUM+'_'+MISS_NUM+'.pt')\n",
        "\n",
        "    if epoch == 0 or (epoch+1) % 100 == 0:\n",
        "        print(\"epoch: {}\".format(epoch+1).ljust(15), end=\"\")\n",
        "        print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "        print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "        print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "        print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMQNjWCYmeO9",
        "outputId": "c7c5a563-3f93-4285-8ad1-783c8a7758d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1       NRMSE_train: 59.11%      NMAE_train: 51.25%       NRMSE_val: 58.85%        NMAE_val: 51.09%         NRMSE_test: 58.25%       NMAE_test: 50.61%        \n",
            "epoch: 100     NRMSE_train: 11.63%      NMAE_train: 8.9%         NRMSE_val: 10.92%        NMAE_val: 8.82%          NRMSE_test: 10.53%       NMAE_test: 8.41%         \n",
            "epoch: 200     NRMSE_train: 8.7%        NMAE_train: 6.85%        NRMSE_val: 6.86%         NMAE_val: 5.5%           NRMSE_test: 8.23%        NMAE_test: 6.29%         \n",
            "epoch: 300     NRMSE_train: 8.22%       NMAE_train: 6.37%        NRMSE_val: 6.34%         NMAE_val: 5.02%          NRMSE_test: 7.94%        NMAE_test: 5.93%         \n",
            "epoch: 400     NRMSE_train: 8.37%       NMAE_train: 6.54%        NRMSE_val: 6.54%         NMAE_val: 5.25%          NRMSE_test: 8.1%         NMAE_test: 6.09%         \n",
            "epoch: 500     NRMSE_train: 8.21%       NMAE_train: 6.4%         NRMSE_val: 6.44%         NMAE_val: 5.15%          NRMSE_test: 7.99%        NMAE_test: 5.98%         \n",
            "epoch: 600     NRMSE_train: 11.06%      NMAE_train: 9.13%        NRMSE_val: 9.72%         NMAE_val: 8.05%          NRMSE_test: 10.64%       NMAE_test: 8.86%         \n",
            "epoch: 700     NRMSE_train: 11.44%      NMAE_train: 9.37%        NRMSE_val: 10.2%         NMAE_val: 8.23%          NRMSE_test: 10.84%       NMAE_test: 9.04%         \n",
            "epoch: 800     NRMSE_train: 11.93%      NMAE_train: 9.88%        NRMSE_val: 10.75%        NMAE_val: 8.74%          NRMSE_test: 11.23%       NMAE_test: 9.42%         \n",
            "epoch: 900     NRMSE_train: 13.09%      NMAE_train: 11.01%       NRMSE_val: 11.98%        NMAE_val: 9.84%          NRMSE_test: 12.42%       NMAE_test: 10.55%        \n",
            "epoch: 1000    NRMSE_train: 14.48%      NMAE_train: 12.41%       NRMSE_val: 13.84%        NMAE_val: 11.61%         NRMSE_test: 14.48%       NMAE_test: 12.36%        \n",
            "epoch: 1100    NRMSE_train: 14.96%      NMAE_train: 12.82%       NRMSE_val: 14.55%        NMAE_val: 12.18%         NRMSE_test: 15.18%       NMAE_test: 12.89%        \n",
            "epoch: 1200    NRMSE_train: 15.19%      NMAE_train: 12.85%       NRMSE_val: 14.92%        NMAE_val: 12.42%         NRMSE_test: 15.75%       NMAE_test: 13.16%        \n",
            "epoch: 1300    NRMSE_train: 17.45%      NMAE_train: 15.0%        NRMSE_val: 17.39%        NMAE_val: 14.98%         NRMSE_test: 18.52%       NMAE_test: 15.77%        \n",
            "epoch: 1400    NRMSE_train: 19.16%      NMAE_train: 16.56%       NRMSE_val: 19.32%        NMAE_val: 16.78%         NRMSE_test: 20.06%       NMAE_test: 17.28%        \n",
            "epoch: 1500    NRMSE_train: 20.28%      NMAE_train: 17.53%       NRMSE_val: 20.74%        NMAE_val: 17.95%         NRMSE_test: 21.41%       NMAE_test: 18.51%        \n",
            "epoch: 1600    NRMSE_train: 21.08%      NMAE_train: 18.16%       NRMSE_val: 21.73%        NMAE_val: 18.71%         NRMSE_test: 22.62%       NMAE_test: 19.55%        \n",
            "epoch: 1700    NRMSE_train: 21.93%      NMAE_train: 19.02%       NRMSE_val: 22.66%        NMAE_val: 19.62%         NRMSE_test: 23.84%       NMAE_test: 20.73%        \n",
            "epoch: 1800    NRMSE_train: 23.91%      NMAE_train: 21.19%       NRMSE_val: 24.57%        NMAE_val: 21.72%         NRMSE_test: 25.95%       NMAE_test: 23.12%        \n",
            "epoch: 1900    NRMSE_train: 24.41%      NMAE_train: 21.59%       NRMSE_val: 25.08%        NMAE_val: 22.1%          NRMSE_test: 26.65%       NMAE_test: 23.76%        \n",
            "epoch: 2000    NRMSE_train: 24.93%      NMAE_train: 22.03%       NRMSE_val: 25.66%        NMAE_val: 22.58%         NRMSE_test: 27.49%       NMAE_test: 24.51%        \n",
            "epoch: 2100    NRMSE_train: 24.64%      NMAE_train: 21.65%       NRMSE_val: 25.5%         NMAE_val: 22.29%         NRMSE_test: 27.36%       NMAE_test: 24.28%        \n",
            "epoch: 2200    NRMSE_train: 25.27%      NMAE_train: 22.33%       NRMSE_val: 26.33%        NMAE_val: 23.12%         NRMSE_test: 28.12%       NMAE_test: 25.08%        \n",
            "epoch: 2300    NRMSE_train: 25.11%      NMAE_train: 22.13%       NRMSE_val: 26.3%         NMAE_val: 22.98%         NRMSE_test: 28.13%       NMAE_test: 25.02%        \n",
            "epoch: 2400    NRMSE_train: 25.33%      NMAE_train: 22.36%       NRMSE_val: 26.75%        NMAE_val: 23.39%         NRMSE_test: 28.3%        NMAE_test: 25.22%        \n",
            "epoch: 2500    NRMSE_train: 25.33%      NMAE_train: 22.28%       NRMSE_val: 26.83%        NMAE_val: 23.4%          NRMSE_test: 28.43%       NMAE_test: 25.28%        \n",
            "epoch: 2600    NRMSE_train: 25.28%      NMAE_train: 22.27%       NRMSE_val: 26.97%        NMAE_val: 23.53%         NRMSE_test: 28.47%       NMAE_test: 25.34%        \n",
            "epoch: 2700    NRMSE_train: 25.61%      NMAE_train: 22.55%       NRMSE_val: 27.45%        NMAE_val: 23.93%         NRMSE_test: 28.94%       NMAE_test: 25.75%        \n",
            "epoch: 2800    NRMSE_train: 25.53%      NMAE_train: 22.5%        NRMSE_val: 27.49%        NMAE_val: 23.95%         NRMSE_test: 28.99%       NMAE_test: 25.81%        \n",
            "epoch: 2900    NRMSE_train: 25.43%      NMAE_train: 22.36%       NRMSE_val: 27.45%        NMAE_val: 23.93%         NRMSE_test: 28.78%       NMAE_test: 25.61%        \n",
            "epoch: 3000    NRMSE_train: 25.22%      NMAE_train: 22.02%       NRMSE_val: 27.53%        NMAE_val: 23.86%         NRMSE_test: 28.8%        NMAE_test: 25.52%        \n",
            "epoch: 3100    NRMSE_train: 25.32%      NMAE_train: 22.07%       NRMSE_val: 27.64%        NMAE_val: 23.9%          NRMSE_test: 29.29%       NMAE_test: 25.87%        \n",
            "epoch: 3200    NRMSE_train: 24.94%      NMAE_train: 21.66%       NRMSE_val: 27.42%        NMAE_val: 23.62%         NRMSE_test: 28.98%       NMAE_test: 25.52%        \n",
            "epoch: 3300    NRMSE_train: 24.83%      NMAE_train: 21.39%       NRMSE_val: 27.46%        NMAE_val: 23.46%         NRMSE_test: 29.22%       NMAE_test: 25.55%        \n",
            "epoch: 3400    NRMSE_train: 24.76%      NMAE_train: 21.29%       NRMSE_val: 27.56%        NMAE_val: 23.52%         NRMSE_test: 29.36%       NMAE_test: 25.63%        \n",
            "epoch: 3500    NRMSE_train: 24.83%      NMAE_train: 21.29%       NRMSE_val: 27.79%        NMAE_val: 23.74%         NRMSE_test: 29.71%       NMAE_test: 25.88%        \n",
            "epoch: 3600    NRMSE_train: 24.47%      NMAE_train: 20.92%       NRMSE_val: 27.65%        NMAE_val: 23.49%         NRMSE_test: 29.67%       NMAE_test: 25.8%         \n",
            "epoch: 3700    NRMSE_train: 24.31%      NMAE_train: 20.59%       NRMSE_val: 27.72%        NMAE_val: 23.38%         NRMSE_test: 29.75%       NMAE_test: 25.69%        \n",
            "epoch: 3800    NRMSE_train: 24.19%      NMAE_train: 20.49%       NRMSE_val: 27.85%        NMAE_val: 23.5%          NRMSE_test: 29.87%       NMAE_test: 25.83%        \n",
            "epoch: 3900    NRMSE_train: 24.0%       NMAE_train: 20.3%        NRMSE_val: 27.8%         NMAE_val: 23.44%         NRMSE_test: 29.94%       NMAE_test: 25.9%         \n",
            "epoch: 4000    NRMSE_train: 23.68%      NMAE_train: 19.81%       NRMSE_val: 27.72%        NMAE_val: 23.17%         NRMSE_test: 29.9%        NMAE_test: 25.65%        \n",
            "epoch: 4100    NRMSE_train: 23.85%      NMAE_train: 20.09%       NRMSE_val: 28.0%         NMAE_val: 23.57%         NRMSE_test: 30.23%       NMAE_test: 26.09%        \n",
            "epoch: 4200    NRMSE_train: 23.77%      NMAE_train: 19.8%        NRMSE_val: 28.42%        NMAE_val: 23.67%         NRMSE_test: 30.83%       NMAE_test: 26.35%        \n",
            "epoch: 4300    NRMSE_train: 23.39%      NMAE_train: 19.43%       NRMSE_val: 28.14%        NMAE_val: 23.47%         NRMSE_test: 30.59%       NMAE_test: 26.11%        \n",
            "epoch: 4400    NRMSE_train: 23.16%      NMAE_train: 19.15%       NRMSE_val: 28.2%         NMAE_val: 23.41%         NRMSE_test: 30.63%       NMAE_test: 26.04%        \n",
            "epoch: 4500    NRMSE_train: 23.19%      NMAE_train: 19.18%       NRMSE_val: 28.36%        NMAE_val: 23.55%         NRMSE_test: 30.85%       NMAE_test: 26.27%        \n",
            "epoch: 4600    NRMSE_train: 22.76%      NMAE_train: 18.67%       NRMSE_val: 28.25%        NMAE_val: 23.29%         NRMSE_test: 30.82%       NMAE_test: 26.09%        \n",
            "epoch: 4700    NRMSE_train: 22.92%      NMAE_train: 18.81%       NRMSE_val: 28.75%        NMAE_val: 23.76%         NRMSE_test: 31.35%       NMAE_test: 26.56%        \n",
            "epoch: 4800    NRMSE_train: 22.48%      NMAE_train: 18.36%       NRMSE_val: 28.57%        NMAE_val: 23.48%         NRMSE_test: 31.18%       NMAE_test: 26.29%        \n",
            "epoch: 4900    NRMSE_train: 22.32%      NMAE_train: 18.2%        NRMSE_val: 28.6%         NMAE_val: 23.5%          NRMSE_test: 31.24%       NMAE_test: 26.31%        \n",
            "epoch: 5000    NRMSE_train: 22.22%      NMAE_train: 18.12%       NRMSE_val: 28.84%        NMAE_val: 23.7%          NRMSE_test: 31.48%       NMAE_test: 26.51%        \n",
            "epoch: 5100    NRMSE_train: 22.11%      NMAE_train: 17.84%       NRMSE_val: 29.06%        NMAE_val: 23.76%         NRMSE_test: 31.93%       NMAE_test: 26.68%        \n",
            "epoch: 5200    NRMSE_train: 21.91%      NMAE_train: 17.8%        NRMSE_val: 29.09%        NMAE_val: 23.9%          NRMSE_test: 31.86%       NMAE_test: 26.74%        \n",
            "epoch: 5300    NRMSE_train: 21.59%      NMAE_train: 17.4%        NRMSE_val: 29.31%        NMAE_val: 23.96%         NRMSE_test: 31.95%       NMAE_test: 26.61%        \n",
            "epoch: 5400    NRMSE_train: 21.43%      NMAE_train: 17.22%       NRMSE_val: 29.25%        NMAE_val: 23.82%         NRMSE_test: 31.92%       NMAE_test: 26.63%        \n",
            "epoch: 5500    NRMSE_train: 21.3%       NMAE_train: 17.15%       NRMSE_val: 29.4%         NMAE_val: 23.98%         NRMSE_test: 31.96%       NMAE_test: 26.68%        \n",
            "epoch: 5600    NRMSE_train: 20.92%      NMAE_train: 16.76%       NRMSE_val: 29.33%        NMAE_val: 23.89%         NRMSE_test: 32.07%       NMAE_test: 26.67%        \n",
            "epoch: 5700    NRMSE_train: 21.01%      NMAE_train: 16.81%       NRMSE_val: 29.75%        NMAE_val: 24.24%         NRMSE_test: 32.5%        NMAE_test: 26.97%        \n",
            "epoch: 5800    NRMSE_train: 20.77%      NMAE_train: 16.59%       NRMSE_val: 29.79%        NMAE_val: 24.24%         NRMSE_test: 32.44%       NMAE_test: 26.93%        \n",
            "epoch: 5900    NRMSE_train: 20.53%      NMAE_train: 16.32%       NRMSE_val: 30.02%        NMAE_val: 24.42%         NRMSE_test: 32.29%       NMAE_test: 26.82%        \n",
            "epoch: 6000    NRMSE_train: 20.07%      NMAE_train: 15.8%        NRMSE_val: 29.88%        NMAE_val: 23.99%         NRMSE_test: 32.35%       NMAE_test: 26.62%        \n",
            "epoch: 6100    NRMSE_train: 19.82%      NMAE_train: 15.66%       NRMSE_val: 29.86%        NMAE_val: 24.15%         NRMSE_test: 32.16%       NMAE_test: 26.56%        \n",
            "epoch: 6200    NRMSE_train: 19.94%      NMAE_train: 15.73%       NRMSE_val: 30.45%        NMAE_val: 24.57%         NRMSE_test: 32.66%       NMAE_test: 26.98%        \n",
            "epoch: 6300    NRMSE_train: 19.57%      NMAE_train: 15.5%        NRMSE_val: 30.25%        NMAE_val: 24.44%         NRMSE_test: 32.4%        NMAE_test: 26.83%        \n",
            "epoch: 6400    NRMSE_train: 19.48%      NMAE_train: 15.34%       NRMSE_val: 30.45%        NMAE_val: 24.55%         NRMSE_test: 32.69%       NMAE_test: 26.98%        \n",
            "epoch: 6500    NRMSE_train: 19.08%      NMAE_train: 14.93%       NRMSE_val: 30.34%        NMAE_val: 24.25%         NRMSE_test: 32.41%       NMAE_test: 26.69%        \n",
            "epoch: 6600    NRMSE_train: 19.16%      NMAE_train: 15.06%       NRMSE_val: 30.72%        NMAE_val: 24.66%         NRMSE_test: 32.79%       NMAE_test: 27.08%        \n",
            "epoch: 6700    NRMSE_train: 18.71%      NMAE_train: 14.65%       NRMSE_val: 30.58%        NMAE_val: 24.54%         NRMSE_test: 32.51%       NMAE_test: 26.79%        \n",
            "epoch: 6800    NRMSE_train: 18.61%      NMAE_train: 14.52%       NRMSE_val: 30.94%        NMAE_val: 24.66%         NRMSE_test: 32.77%       NMAE_test: 27.0%         \n",
            "epoch: 6900    NRMSE_train: 18.47%      NMAE_train: 14.31%       NRMSE_val: 30.73%        NMAE_val: 24.58%         NRMSE_test: 32.68%       NMAE_test: 26.87%        \n",
            "epoch: 7000    NRMSE_train: 18.25%      NMAE_train: 14.12%       NRMSE_val: 30.94%        NMAE_val: 24.63%         NRMSE_test: 32.81%       NMAE_test: 26.95%        \n",
            "epoch: 7100    NRMSE_train: 18.01%      NMAE_train: 13.92%       NRMSE_val: 30.98%        NMAE_val: 24.56%         NRMSE_test: 32.89%       NMAE_test: 27.04%        \n",
            "epoch: 7200    NRMSE_train: 17.73%      NMAE_train: 13.52%       NRMSE_val: 30.91%        NMAE_val: 24.39%         NRMSE_test: 33.02%       NMAE_test: 26.94%        \n",
            "epoch: 7300    NRMSE_train: 17.64%      NMAE_train: 13.53%       NRMSE_val: 31.18%        NMAE_val: 24.73%         NRMSE_test: 33.02%       NMAE_test: 27.05%        \n",
            "epoch: 7400    NRMSE_train: 17.34%      NMAE_train: 13.32%       NRMSE_val: 30.97%        NMAE_val: 24.54%         NRMSE_test: 32.96%       NMAE_test: 26.95%        \n",
            "epoch: 7500    NRMSE_train: 17.15%      NMAE_train: 13.11%       NRMSE_val: 30.98%        NMAE_val: 24.41%         NRMSE_test: 32.93%       NMAE_test: 26.85%        \n",
            "epoch: 7600    NRMSE_train: 16.95%      NMAE_train: 12.96%       NRMSE_val: 31.05%        NMAE_val: 24.49%         NRMSE_test: 33.01%       NMAE_test: 26.9%         \n",
            "epoch: 7700    NRMSE_train: 16.97%      NMAE_train: 13.04%       NRMSE_val: 31.18%        NMAE_val: 24.61%         NRMSE_test: 33.28%       NMAE_test: 27.19%        \n",
            "epoch: 7800    NRMSE_train: 16.53%      NMAE_train: 12.53%       NRMSE_val: 31.22%        NMAE_val: 24.43%         NRMSE_test: 33.02%       NMAE_test: 26.77%        \n",
            "epoch: 7900    NRMSE_train: 16.58%      NMAE_train: 12.65%       NRMSE_val: 31.27%        NMAE_val: 24.55%         NRMSE_test: 33.28%       NMAE_test: 27.11%        \n",
            "epoch: 8000    NRMSE_train: 16.29%      NMAE_train: 12.39%       NRMSE_val: 30.83%        NMAE_val: 24.27%         NRMSE_test: 33.1%        NMAE_test: 26.82%        \n",
            "epoch: 8100    NRMSE_train: 16.18%      NMAE_train: 12.21%       NRMSE_val: 31.34%        NMAE_val: 24.72%         NRMSE_test: 33.21%       NMAE_test: 26.93%        \n",
            "epoch: 8200    NRMSE_train: 16.01%      NMAE_train: 12.16%       NRMSE_val: 31.26%        NMAE_val: 24.59%         NRMSE_test: 33.36%       NMAE_test: 27.06%        \n",
            "epoch: 8300    NRMSE_train: 15.65%      NMAE_train: 11.78%       NRMSE_val: 31.01%        NMAE_val: 24.22%         NRMSE_test: 32.87%       NMAE_test: 26.61%        \n",
            "epoch: 8400    NRMSE_train: 15.57%      NMAE_train: 11.72%       NRMSE_val: 31.14%        NMAE_val: 24.35%         NRMSE_test: 33.05%       NMAE_test: 26.74%        \n",
            "epoch: 8500    NRMSE_train: 15.41%      NMAE_train: 11.6%        NRMSE_val: 31.04%        NMAE_val: 24.21%         NRMSE_test: 33.24%       NMAE_test: 26.9%         \n",
            "epoch: 8600    NRMSE_train: 15.43%      NMAE_train: 11.63%       NRMSE_val: 31.32%        NMAE_val: 24.42%         NRMSE_test: 33.5%        NMAE_test: 27.11%        \n",
            "epoch: 8700    NRMSE_train: 15.26%      NMAE_train: 11.42%       NRMSE_val: 31.5%         NMAE_val: 24.54%         NRMSE_test: 33.54%       NMAE_test: 27.01%        \n",
            "epoch: 8800    NRMSE_train: 15.01%      NMAE_train: 11.28%       NRMSE_val: 31.29%        NMAE_val: 24.28%         NRMSE_test: 33.34%       NMAE_test: 26.91%        \n",
            "epoch: 8900    NRMSE_train: 14.98%      NMAE_train: 11.2%        NRMSE_val: 31.54%        NMAE_val: 24.54%         NRMSE_test: 33.42%       NMAE_test: 26.99%        \n",
            "epoch: 9000    NRMSE_train: 14.81%      NMAE_train: 11.09%       NRMSE_val: 31.57%        NMAE_val: 24.52%         NRMSE_test: 33.56%       NMAE_test: 27.08%        \n",
            "epoch: 9100    NRMSE_train: 14.63%      NMAE_train: 10.85%       NRMSE_val: 31.19%        NMAE_val: 24.19%         NRMSE_test: 33.51%       NMAE_test: 26.93%        \n",
            "epoch: 9200    NRMSE_train: 14.47%      NMAE_train: 10.77%       NRMSE_val: 31.3%         NMAE_val: 24.28%         NRMSE_test: 33.54%       NMAE_test: 27.01%        \n",
            "epoch: 9300    NRMSE_train: 14.43%      NMAE_train: 10.71%       NRMSE_val: 31.51%        NMAE_val: 24.46%         NRMSE_test: 33.59%       NMAE_test: 27.02%        \n",
            "epoch: 9400    NRMSE_train: 14.38%      NMAE_train: 10.73%       NRMSE_val: 31.39%        NMAE_val: 24.28%         NRMSE_test: 33.65%       NMAE_test: 27.13%        \n",
            "epoch: 9500    NRMSE_train: 14.28%      NMAE_train: 10.59%       NRMSE_val: 31.35%        NMAE_val: 24.23%         NRMSE_test: 33.62%       NMAE_test: 26.99%        \n",
            "epoch: 9600    NRMSE_train: 14.05%      NMAE_train: 10.35%       NRMSE_val: 31.6%         NMAE_val: 24.35%         NRMSE_test: 33.56%       NMAE_test: 26.95%        \n",
            "epoch: 9700    NRMSE_train: 14.1%       NMAE_train: 10.44%       NRMSE_val: 31.47%        NMAE_val: 24.25%         NRMSE_test: 33.67%       NMAE_test: 27.07%        \n",
            "epoch: 9800    NRMSE_train: 13.71%      NMAE_train: 10.1%        NRMSE_val: 31.54%        NMAE_val: 24.24%         NRMSE_test: 33.49%       NMAE_test: 26.9%         \n",
            "epoch: 9900    NRMSE_train: 13.83%      NMAE_train: 10.19%       NRMSE_val: 31.84%        NMAE_val: 24.54%         NRMSE_test: 33.72%       NMAE_test: 27.07%        \n",
            "epoch: 10000   NRMSE_train: 13.64%      NMAE_train: 10.04%       NRMSE_val: 31.88%        NMAE_val: 24.64%         NRMSE_test: 33.94%       NMAE_test: 27.12%        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoising AutoEncoder (Test)\n",
        "\n",
        "batch_size = 128\n",
        "total_batch = int(len(data_train_miss)/batch_size) + 1\n",
        "\n",
        "dae = AED()\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "\n",
        "dae.load_state_dict(torch.load('DAE_'+DATA_NUM+'_'+MISS_NUM+'.pt'))\n",
        "\n",
        "data_train_DAE = dae.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_val_DAE   = dae.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_test_DAE  = dae.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "data_train_DAE[data_train_miss - data_train_miss2 == 0] = 0\n",
        "data_val_DAE[data_val_miss - data_val_miss2 == 0] = 0\n",
        "data_test_DAE[data_test_miss != 0] = 0\n",
        "\n",
        "mse_train += [np.mean(np.square(data_train_DAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mae_train += [np.mean(np.abs(data_train_DAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mse_val += [np.mean(np.square(data_val_DAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mae_val += [np.mean(np.abs(data_val_DAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mse_test += [np.mean(np.square(data_test_DAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "mae_test += [np.mean(np.abs(data_test_DAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "NMAE_train  = round(100*mae_train[-1],2)\n",
        "NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "NMAE_val  = round(100*mae_val[-1],2)\n",
        "NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT03nmZjmw-u",
        "outputId": "ef14f39d-4886-4391-b351-14713c446f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRMSE_train: 7.78%       NMAE_train: 5.94%        NRMSE_val: 5.88%         NMAE_val: 4.59%          NRMSE_test: 7.62%        NMAE_test: 5.53%         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked AutoEncoder (Training)\n",
        "\n",
        "batch_size1 = 128\n",
        "total_batch1 = int(len(data_train_miss)/batch_size1) + 1\n",
        "batch_size2 = 32\n",
        "total_batch2 = int(len(data_val_miss)/batch_size2) + 1\n",
        "\n",
        "mae = AED()\n",
        "optimizer = optim.Adam(mae.parameters(), lr = 0.001)\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "for epoch in range(10000):\n",
        "    for i in range(total_batch1):\n",
        "        batch_x = torch.tensor(data_test_miss[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch_y = torch.tensor(data_test_miss[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch = [batch_x, batch_y]\n",
        "        train_MAE(mae, batch, optimizer)\n",
        "\n",
        "    data_train_MAE = mae.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_val_MAE   = mae.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_test_MAE  = mae.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "    data_train_MAE[data_train_miss - data_train_miss2 == 0] = 0\n",
        "    data_val_MAE[data_val_miss - data_val_miss2 == 0] = 0\n",
        "    data_test_MAE[data_test_miss != 0] = 0\n",
        "\n",
        "    mse_train += [np.mean(np.square(data_train_MAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mae_train += [np.mean(np.abs(data_train_MAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mse_val += [np.mean(np.square(data_val_MAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mae_val += [np.mean(np.abs(data_val_MAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mse_test += [np.mean(np.square(data_test_MAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "    mae_test += [np.mean(np.abs(data_test_MAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "    NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "    NMAE_train  = round(100*mae_train[-1],2)\n",
        "    NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "    NMAE_val  = round(100*mae_val[-1],2)\n",
        "    NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "    NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "    if mse_val[-1] == np.min(mse_val):\n",
        "        torch.save(mae.state_dict(), 'MAE_'+DATA_NUM+'_'+MISS_NUM+'.pt')\n",
        "\n",
        "    if epoch == 0 or (epoch+1) % 100 == 0:\n",
        "        print(\"epoch: {}\".format(epoch+1).ljust(15), end=\"\")\n",
        "        print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "        print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "        print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "        print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBS_bbM8aIm-",
        "outputId": "788a910b-2bbf-49b4-bce5-aa9c3f1bcfd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1       NRMSE_train: 58.4%       NMAE_train: 50.59%       NRMSE_val: 57.21%        NMAE_val: 49.27%         NRMSE_test: 56.56%       NMAE_test: 49.34%        \n",
            "epoch: 100     NRMSE_train: 12.05%      NMAE_train: 8.86%        NRMSE_val: 12.33%        NMAE_val: 8.99%          NRMSE_test: 11.06%       NMAE_test: 8.33%         \n",
            "epoch: 200     NRMSE_train: 8.26%       NMAE_train: 6.16%        NRMSE_val: 7.44%         NMAE_val: 5.55%          NRMSE_test: 7.56%        NMAE_test: 5.22%         \n",
            "epoch: 300     NRMSE_train: 7.15%       NMAE_train: 5.34%        NRMSE_val: 6.06%         NMAE_val: 4.71%          NRMSE_test: 7.55%        NMAE_test: 5.31%         \n",
            "epoch: 400     NRMSE_train: 7.11%       NMAE_train: 5.34%        NRMSE_val: 5.48%         NMAE_val: 4.06%          NRMSE_test: 7.13%        NMAE_test: 4.71%         \n",
            "epoch: 500     NRMSE_train: 6.86%       NMAE_train: 5.11%        NRMSE_val: 5.3%          NMAE_val: 3.97%          NRMSE_test: 7.11%        NMAE_test: 4.77%         \n",
            "epoch: 600     NRMSE_train: 6.79%       NMAE_train: 5.02%        NRMSE_val: 5.3%          NMAE_val: 4.03%          NRMSE_test: 7.21%        NMAE_test: 4.92%         \n",
            "epoch: 700     NRMSE_train: 6.77%       NMAE_train: 5.01%        NRMSE_val: 5.3%          NMAE_val: 4.07%          NRMSE_test: 7.29%        NMAE_test: 5.02%         \n",
            "epoch: 800     NRMSE_train: 6.72%       NMAE_train: 4.95%        NRMSE_val: 5.2%          NMAE_val: 3.96%          NRMSE_test: 7.27%        NMAE_test: 4.99%         \n",
            "epoch: 900     NRMSE_train: 6.68%       NMAE_train: 4.88%        NRMSE_val: 5.08%         NMAE_val: 3.8%           NRMSE_test: 7.15%        NMAE_test: 4.81%         \n",
            "epoch: 1000    NRMSE_train: 6.74%       NMAE_train: 4.95%        NRMSE_val: 5.05%         NMAE_val: 3.71%          NRMSE_test: 7.05%        NMAE_test: 4.69%         \n",
            "epoch: 1100    NRMSE_train: 6.93%       NMAE_train: 5.11%        NRMSE_val: 5.19%         NMAE_val: 3.77%          NRMSE_test: 7.03%        NMAE_test: 4.69%         \n",
            "epoch: 1200    NRMSE_train: 6.7%        NMAE_train: 4.92%        NRMSE_val: 5.08%         NMAE_val: 3.7%           NRMSE_test: 6.87%        NMAE_test: 4.58%         \n",
            "epoch: 1300    NRMSE_train: 6.82%       NMAE_train: 5.05%        NRMSE_val: 5.39%         NMAE_val: 3.86%          NRMSE_test: 6.57%        NMAE_test: 4.49%         \n",
            "epoch: 1400    NRMSE_train: 7.43%       NMAE_train: 5.47%        NRMSE_val: 6.14%         NMAE_val: 4.2%           NRMSE_test: 6.39%        NMAE_test: 4.6%          \n",
            "epoch: 1500    NRMSE_train: 7.82%       NMAE_train: 5.66%        NRMSE_val: 6.58%         NMAE_val: 4.41%          NRMSE_test: 6.48%        NMAE_test: 4.67%         \n",
            "epoch: 1600    NRMSE_train: 7.65%       NMAE_train: 5.51%        NRMSE_val: 6.47%         NMAE_val: 4.35%          NRMSE_test: 6.43%        NMAE_test: 4.58%         \n",
            "epoch: 1700    NRMSE_train: 7.81%       NMAE_train: 5.59%        NRMSE_val: 6.66%         NMAE_val: 4.47%          NRMSE_test: 6.62%        NMAE_test: 4.7%          \n",
            "epoch: 1800    NRMSE_train: 8.44%       NMAE_train: 6.08%        NRMSE_val: 7.19%         NMAE_val: 4.9%           NRMSE_test: 6.88%        NMAE_test: 4.85%         \n",
            "epoch: 1900    NRMSE_train: 8.04%       NMAE_train: 5.67%        NRMSE_val: 6.85%         NMAE_val: 4.47%          NRMSE_test: 6.82%        NMAE_test: 4.73%         \n",
            "epoch: 2000    NRMSE_train: 7.86%       NMAE_train: 5.54%        NRMSE_val: 6.7%          NMAE_val: 4.43%          NRMSE_test: 6.87%        NMAE_test: 4.7%          \n",
            "epoch: 2100    NRMSE_train: 8.04%       NMAE_train: 5.63%        NRMSE_val: 6.87%         NMAE_val: 4.49%          NRMSE_test: 6.98%        NMAE_test: 4.73%         \n",
            "epoch: 2200    NRMSE_train: 7.97%       NMAE_train: 5.59%        NRMSE_val: 6.83%         NMAE_val: 4.47%          NRMSE_test: 7.03%        NMAE_test: 4.72%         \n",
            "epoch: 2300    NRMSE_train: 8.03%       NMAE_train: 5.61%        NRMSE_val: 6.89%         NMAE_val: 4.52%          NRMSE_test: 7.08%        NMAE_test: 4.76%         \n",
            "epoch: 2400    NRMSE_train: 7.57%       NMAE_train: 5.36%        NRMSE_val: 6.57%         NMAE_val: 4.5%           NRMSE_test: 7.2%         NMAE_test: 4.88%         \n",
            "epoch: 2500    NRMSE_train: 7.9%        NMAE_train: 5.49%        NRMSE_val: 6.81%         NMAE_val: 4.47%          NRMSE_test: 7.21%        NMAE_test: 4.75%         \n",
            "epoch: 2600    NRMSE_train: 7.97%       NMAE_train: 5.55%        NRMSE_val: 6.92%         NMAE_val: 4.53%          NRMSE_test: 7.21%        NMAE_test: 4.73%         \n",
            "epoch: 2700    NRMSE_train: 7.68%       NMAE_train: 5.38%        NRMSE_val: 6.7%          NMAE_val: 4.48%          NRMSE_test: 7.29%        NMAE_test: 4.81%         \n",
            "epoch: 2800    NRMSE_train: 8.13%       NMAE_train: 5.66%        NRMSE_val: 7.07%         NMAE_val: 4.62%          NRMSE_test: 7.34%        NMAE_test: 4.82%         \n",
            "epoch: 2900    NRMSE_train: 8.32%       NMAE_train: 5.77%        NRMSE_val: 7.29%         NMAE_val: 4.71%          NRMSE_test: 7.44%        NMAE_test: 4.84%         \n",
            "epoch: 3000    NRMSE_train: 8.38%       NMAE_train: 5.83%        NRMSE_val: 7.33%         NMAE_val: 4.78%          NRMSE_test: 7.58%        NMAE_test: 4.92%         \n",
            "epoch: 3100    NRMSE_train: 7.9%        NMAE_train: 5.47%        NRMSE_val: 6.96%         NMAE_val: 4.53%          NRMSE_test: 7.39%        NMAE_test: 4.78%         \n",
            "epoch: 3200    NRMSE_train: 8.17%       NMAE_train: 5.68%        NRMSE_val: 7.21%         NMAE_val: 4.7%           NRMSE_test: 7.44%        NMAE_test: 4.81%         \n",
            "epoch: 3300    NRMSE_train: 8.01%       NMAE_train: 5.49%        NRMSE_val: 7.17%         NMAE_val: 4.61%          NRMSE_test: 7.55%        NMAE_test: 4.85%         \n",
            "epoch: 3400    NRMSE_train: 7.8%        NMAE_train: 5.41%        NRMSE_val: 7.0%          NMAE_val: 4.56%          NRMSE_test: 7.44%        NMAE_test: 4.81%         \n",
            "epoch: 3500    NRMSE_train: 8.09%       NMAE_train: 5.58%        NRMSE_val: 7.24%         NMAE_val: 4.63%          NRMSE_test: 7.43%        NMAE_test: 4.77%         \n",
            "epoch: 3600    NRMSE_train: 7.62%       NMAE_train: 5.31%        NRMSE_val: 6.9%          NMAE_val: 4.54%          NRMSE_test: 7.39%        NMAE_test: 4.78%         \n",
            "epoch: 3700    NRMSE_train: 8.05%       NMAE_train: 5.58%        NRMSE_val: 7.22%         NMAE_val: 4.7%           NRMSE_test: 7.45%        NMAE_test: 4.78%         \n",
            "epoch: 3800    NRMSE_train: 7.97%       NMAE_train: 5.55%        NRMSE_val: 7.23%         NMAE_val: 4.65%          NRMSE_test: 7.31%        NMAE_test: 4.69%         \n",
            "epoch: 3900    NRMSE_train: 7.62%       NMAE_train: 5.32%        NRMSE_val: 7.02%         NMAE_val: 4.56%          NRMSE_test: 7.39%        NMAE_test: 4.7%          \n",
            "epoch: 4000    NRMSE_train: 7.72%       NMAE_train: 5.38%        NRMSE_val: 7.15%         NMAE_val: 4.59%          NRMSE_test: 7.34%        NMAE_test: 4.67%         \n",
            "epoch: 4100    NRMSE_train: 7.43%       NMAE_train: 5.2%         NRMSE_val: 7.03%         NMAE_val: 4.52%          NRMSE_test: 7.23%        NMAE_test: 4.62%         \n",
            "epoch: 4200    NRMSE_train: 7.23%       NMAE_train: 5.11%        NRMSE_val: 6.91%         NMAE_val: 4.48%          NRMSE_test: 7.03%        NMAE_test: 4.55%         \n",
            "epoch: 4300    NRMSE_train: 6.93%       NMAE_train: 5.03%        NRMSE_val: 6.71%         NMAE_val: 4.53%          NRMSE_test: 7.16%        NMAE_test: 4.7%          \n",
            "epoch: 4400    NRMSE_train: 7.36%       NMAE_train: 5.21%        NRMSE_val: 7.09%         NMAE_val: 4.5%           NRMSE_test: 7.06%        NMAE_test: 4.45%         \n",
            "epoch: 4500    NRMSE_train: 6.86%       NMAE_train: 4.93%        NRMSE_val: 6.6%          NMAE_val: 4.35%          NRMSE_test: 6.93%        NMAE_test: 4.44%         \n",
            "epoch: 4600    NRMSE_train: 7.04%       NMAE_train: 5.04%        NRMSE_val: 6.66%         NMAE_val: 4.35%          NRMSE_test: 6.93%        NMAE_test: 4.32%         \n",
            "epoch: 4700    NRMSE_train: 6.98%       NMAE_train: 5.03%        NRMSE_val: 6.65%         NMAE_val: 4.36%          NRMSE_test: 6.73%        NMAE_test: 4.26%         \n",
            "epoch: 4800    NRMSE_train: 6.67%       NMAE_train: 4.84%        NRMSE_val: 6.4%          NMAE_val: 4.26%          NRMSE_test: 6.82%        NMAE_test: 4.25%         \n",
            "epoch: 4900    NRMSE_train: 6.72%       NMAE_train: 4.87%        NRMSE_val: 6.36%         NMAE_val: 4.22%          NRMSE_test: 6.82%        NMAE_test: 4.21%         \n",
            "epoch: 5000    NRMSE_train: 6.91%       NMAE_train: 5.0%         NRMSE_val: 6.46%         NMAE_val: 4.31%          NRMSE_test: 6.75%        NMAE_test: 4.14%         \n",
            "epoch: 5100    NRMSE_train: 6.6%        NMAE_train: 4.81%        NRMSE_val: 6.15%         NMAE_val: 4.12%          NRMSE_test: 6.86%        NMAE_test: 4.2%          \n",
            "epoch: 5200    NRMSE_train: 6.56%       NMAE_train: 4.8%         NRMSE_val: 6.17%         NMAE_val: 4.17%          NRMSE_test: 6.8%         NMAE_test: 4.22%         \n",
            "epoch: 5300    NRMSE_train: 6.65%       NMAE_train: 4.83%        NRMSE_val: 6.26%         NMAE_val: 4.14%          NRMSE_test: 6.73%        NMAE_test: 4.09%         \n",
            "epoch: 5400    NRMSE_train: 6.8%        NMAE_train: 4.94%        NRMSE_val: 6.34%         NMAE_val: 4.21%          NRMSE_test: 6.87%        NMAE_test: 4.19%         \n",
            "epoch: 5500    NRMSE_train: 6.56%       NMAE_train: 4.78%        NRMSE_val: 6.23%         NMAE_val: 4.12%          NRMSE_test: 6.88%        NMAE_test: 4.12%         \n",
            "epoch: 5600    NRMSE_train: 6.95%       NMAE_train: 5.06%        NRMSE_val: 6.53%         NMAE_val: 4.32%          NRMSE_test: 7.03%        NMAE_test: 4.23%         \n",
            "epoch: 5700    NRMSE_train: 6.62%       NMAE_train: 4.84%        NRMSE_val: 6.21%         NMAE_val: 4.12%          NRMSE_test: 6.83%        NMAE_test: 4.1%          \n",
            "epoch: 5800    NRMSE_train: 6.7%        NMAE_train: 4.88%        NRMSE_val: 6.12%         NMAE_val: 4.15%          NRMSE_test: 6.87%        NMAE_test: 4.08%         \n",
            "epoch: 5900    NRMSE_train: 6.38%       NMAE_train: 4.69%        NRMSE_val: 6.05%         NMAE_val: 4.11%          NRMSE_test: 6.97%        NMAE_test: 4.24%         \n",
            "epoch: 6000    NRMSE_train: 6.56%       NMAE_train: 4.79%        NRMSE_val: 6.2%          NMAE_val: 4.11%          NRMSE_test: 6.89%        NMAE_test: 4.09%         \n",
            "epoch: 6100    NRMSE_train: 6.41%       NMAE_train: 4.69%        NRMSE_val: 6.03%         NMAE_val: 4.07%          NRMSE_test: 6.99%        NMAE_test: 4.14%         \n",
            "epoch: 6200    NRMSE_train: 6.74%       NMAE_train: 4.91%        NRMSE_val: 6.22%         NMAE_val: 4.2%           NRMSE_test: 6.95%        NMAE_test: 4.1%          \n",
            "epoch: 6300    NRMSE_train: 6.58%       NMAE_train: 4.79%        NRMSE_val: 6.19%         NMAE_val: 4.1%           NRMSE_test: 7.08%        NMAE_test: 4.15%         \n",
            "epoch: 6400    NRMSE_train: 6.49%       NMAE_train: 4.75%        NRMSE_val: 6.15%         NMAE_val: 4.08%          NRMSE_test: 7.01%        NMAE_test: 4.11%         \n",
            "epoch: 6500    NRMSE_train: 6.56%       NMAE_train: 4.79%        NRMSE_val: 6.11%         NMAE_val: 4.08%          NRMSE_test: 7.11%        NMAE_test: 4.17%         \n",
            "epoch: 6600    NRMSE_train: 6.64%       NMAE_train: 4.84%        NRMSE_val: 6.23%         NMAE_val: 4.12%          NRMSE_test: 7.04%        NMAE_test: 4.13%         \n",
            "epoch: 6700    NRMSE_train: 6.65%       NMAE_train: 4.86%        NRMSE_val: 6.19%         NMAE_val: 4.12%          NRMSE_test: 7.05%        NMAE_test: 4.09%         \n",
            "epoch: 6800    NRMSE_train: 6.63%       NMAE_train: 4.83%        NRMSE_val: 6.19%         NMAE_val: 4.11%          NRMSE_test: 7.02%        NMAE_test: 4.12%         \n",
            "epoch: 6900    NRMSE_train: 6.59%       NMAE_train: 4.84%        NRMSE_val: 6.18%         NMAE_val: 4.1%           NRMSE_test: 7.03%        NMAE_test: 4.11%         \n",
            "epoch: 7000    NRMSE_train: 6.36%       NMAE_train: 4.66%        NRMSE_val: 5.96%         NMAE_val: 4.06%          NRMSE_test: 7.24%        NMAE_test: 4.24%         \n",
            "epoch: 7100    NRMSE_train: 6.58%       NMAE_train: 4.8%         NRMSE_val: 6.21%         NMAE_val: 4.12%          NRMSE_test: 7.21%        NMAE_test: 4.16%         \n",
            "epoch: 7200    NRMSE_train: 6.74%       NMAE_train: 4.92%        NRMSE_val: 6.28%         NMAE_val: 4.18%          NRMSE_test: 7.24%        NMAE_test: 4.17%         \n",
            "epoch: 7300    NRMSE_train: 6.35%       NMAE_train: 4.7%         NRMSE_val: 5.98%         NMAE_val: 4.13%          NRMSE_test: 7.37%        NMAE_test: 4.34%         \n",
            "epoch: 7400    NRMSE_train: 6.51%       NMAE_train: 4.74%        NRMSE_val: 6.27%         NMAE_val: 4.19%          NRMSE_test: 7.44%        NMAE_test: 4.26%         \n",
            "epoch: 7500    NRMSE_train: 6.78%       NMAE_train: 4.91%        NRMSE_val: 6.35%         NMAE_val: 4.21%          NRMSE_test: 7.46%        NMAE_test: 4.21%         \n",
            "epoch: 7600    NRMSE_train: 6.69%       NMAE_train: 4.85%        NRMSE_val: 6.3%          NMAE_val: 4.16%          NRMSE_test: 7.52%        NMAE_test: 4.21%         \n",
            "epoch: 7700    NRMSE_train: 6.58%       NMAE_train: 4.77%        NRMSE_val: 6.16%         NMAE_val: 4.16%          NRMSE_test: 7.64%        NMAE_test: 4.23%         \n",
            "epoch: 7800    NRMSE_train: 6.63%       NMAE_train: 4.81%        NRMSE_val: 6.19%         NMAE_val: 4.1%           NRMSE_test: 7.74%        NMAE_test: 4.21%         \n",
            "epoch: 7900    NRMSE_train: 6.73%       NMAE_train: 4.87%        NRMSE_val: 6.14%         NMAE_val: 4.13%          NRMSE_test: 7.82%        NMAE_test: 4.21%         \n",
            "epoch: 8000    NRMSE_train: 6.59%       NMAE_train: 4.76%        NRMSE_val: 6.09%         NMAE_val: 4.11%          NRMSE_test: 8.03%        NMAE_test: 4.37%         \n",
            "epoch: 8100    NRMSE_train: 6.72%       NMAE_train: 4.82%        NRMSE_val: 6.12%         NMAE_val: 4.1%           NRMSE_test: 8.16%        NMAE_test: 4.28%         \n",
            "epoch: 8200    NRMSE_train: 6.66%       NMAE_train: 4.77%        NRMSE_val: 6.13%         NMAE_val: 4.09%          NRMSE_test: 8.28%        NMAE_test: 4.37%         \n",
            "epoch: 8300    NRMSE_train: 6.7%        NMAE_train: 4.78%        NRMSE_val: 6.09%         NMAE_val: 4.1%           NRMSE_test: 8.41%        NMAE_test: 4.41%         \n",
            "epoch: 8400    NRMSE_train: 7.19%       NMAE_train: 5.14%        NRMSE_val: 6.58%         NMAE_val: 4.36%          NRMSE_test: 8.45%        NMAE_test: 4.47%         \n",
            "epoch: 8500    NRMSE_train: 6.56%       NMAE_train: 4.69%        NRMSE_val: 6.02%         NMAE_val: 4.12%          NRMSE_test: 8.47%        NMAE_test: 4.44%         \n",
            "epoch: 8600    NRMSE_train: 6.85%       NMAE_train: 4.87%        NRMSE_val: 6.21%         NMAE_val: 4.14%          NRMSE_test: 8.6%         NMAE_test: 4.43%         \n",
            "epoch: 8700    NRMSE_train: 6.89%       NMAE_train: 4.87%        NRMSE_val: 6.27%         NMAE_val: 4.18%          NRMSE_test: 8.64%        NMAE_test: 4.36%         \n",
            "epoch: 8800    NRMSE_train: 7.03%       NMAE_train: 4.97%        NRMSE_val: 6.35%         NMAE_val: 4.22%          NRMSE_test: 8.77%        NMAE_test: 4.45%         \n",
            "epoch: 8900    NRMSE_train: 6.87%       NMAE_train: 4.86%        NRMSE_val: 6.28%         NMAE_val: 4.15%          NRMSE_test: 8.72%        NMAE_test: 4.47%         \n",
            "epoch: 9000    NRMSE_train: 6.96%       NMAE_train: 4.91%        NRMSE_val: 6.21%         NMAE_val: 4.19%          NRMSE_test: 8.75%        NMAE_test: 4.37%         \n",
            "epoch: 9100    NRMSE_train: 6.89%       NMAE_train: 4.86%        NRMSE_val: 6.3%          NMAE_val: 4.2%           NRMSE_test: 8.93%        NMAE_test: 4.52%         \n",
            "epoch: 9200    NRMSE_train: 6.86%       NMAE_train: 4.84%        NRMSE_val: 6.24%         NMAE_val: 4.16%          NRMSE_test: 8.91%        NMAE_test: 4.48%         \n",
            "epoch: 9300    NRMSE_train: 7.09%       NMAE_train: 4.98%        NRMSE_val: 6.43%         NMAE_val: 4.28%          NRMSE_test: 8.92%        NMAE_test: 4.43%         \n",
            "epoch: 9400    NRMSE_train: 6.95%       NMAE_train: 4.86%        NRMSE_val: 6.3%          NMAE_val: 4.19%          NRMSE_test: 8.93%        NMAE_test: 4.44%         \n",
            "epoch: 9500    NRMSE_train: 7.25%       NMAE_train: 5.06%        NRMSE_val: 6.56%         NMAE_val: 4.32%          NRMSE_test: 9.1%         NMAE_test: 4.47%         \n",
            "epoch: 9600    NRMSE_train: 6.89%       NMAE_train: 4.84%        NRMSE_val: 6.17%         NMAE_val: 4.17%          NRMSE_test: 9.02%        NMAE_test: 4.5%          \n",
            "epoch: 9700    NRMSE_train: 7.31%       NMAE_train: 5.15%        NRMSE_val: 6.58%         NMAE_val: 4.4%           NRMSE_test: 9.0%         NMAE_test: 4.53%         \n",
            "epoch: 9800    NRMSE_train: 7.26%       NMAE_train: 5.1%         NRMSE_val: 6.61%         NMAE_val: 4.35%          NRMSE_test: 9.0%         NMAE_test: 4.49%         \n",
            "epoch: 9900    NRMSE_train: 6.97%       NMAE_train: 4.89%        NRMSE_val: 6.19%         NMAE_val: 4.12%          NRMSE_test: 8.99%        NMAE_test: 4.44%         \n",
            "epoch: 10000   NRMSE_train: 7.36%       NMAE_train: 5.11%        NRMSE_val: 6.66%         NMAE_val: 4.33%          NRMSE_test: 9.33%        NMAE_test: 4.59%         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked AutoEncoder (Test)\n",
        "\n",
        "batch_size = 128\n",
        "total_batch = int(len(data_train_miss)/batch_size) + 1\n",
        "\n",
        "mae = AED()\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "\n",
        "mae.load_state_dict(torch.load('MAE_'+DATA_NUM+'_'+MISS_NUM+'.pt'))\n",
        "\n",
        "data_train_MAE = mae.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_val_MAE   = mae.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_test_MAE  = mae.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "data_train_MAE[data_train_miss - data_train_miss2 == 0] = 0\n",
        "data_val_MAE[data_val_miss - data_val_miss2 == 0] = 0\n",
        "data_test_MAE[data_test_miss != 0] = 0\n",
        "\n",
        "mse_train += [np.mean(np.square(data_train_MAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mae_train += [np.mean(np.abs(data_train_MAE - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mse_val += [np.mean(np.square(data_val_MAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mae_val += [np.mean(np.abs(data_val_MAE - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mse_test += [np.mean(np.square(data_test_MAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "mae_test += [np.mean(np.abs(data_test_MAE - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "NMAE_train  = round(100*mae_train[-1],2)\n",
        "NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "NMAE_val  = round(100*mae_val[-1],2)\n",
        "NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0rPvA7BaKde",
        "outputId": "bbd86c74-1e57-4370-ab29-0089a00f49d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRMSE_train: 6.71%       NMAE_train: 4.92%        NRMSE_val: 5.01%         NMAE_val: 3.68%          NRMSE_test: 7.04%        NMAE_test: 4.69%         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoising Masked AutoEncoder 1 (Training)\n",
        "\n",
        "batch_size1 = 128\n",
        "total_batch1 = int(len(data_train_miss)/batch_size1) + 1\n",
        "batch_size2 = 32\n",
        "total_batch2 = int(len(data_val_miss)/batch_size2) + 1\n",
        "\n",
        "dmae1 = AED()\n",
        "optimizer = optim.Adam(dmae1.parameters(), lr = 0.001)\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "for epoch in range(20000):\n",
        "    for i in range(total_batch1):\n",
        "        batch_x = torch.tensor(data_train_miss2[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch_y = torch.tensor(data_train_miss[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch = [batch_x, batch_y]\n",
        "        train_MAE(dmae1, batch, optimizer)\n",
        "\n",
        "    data_train_DMAE1 = dmae1.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_val_DMAE1   = dmae1.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_test_DMAE1  = dmae1.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "    data_train_DMAE1[data_train_miss - data_train_miss2 == 0] = 0\n",
        "    data_val_DMAE1[data_val_miss - data_val_miss2 == 0] = 0\n",
        "    data_test_DMAE1[data_test_miss != 0] = 0\n",
        "\n",
        "    mse_train += [np.mean(np.square(data_train_DMAE1 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mae_train += [np.mean(np.abs(data_train_DMAE1 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mse_val += [np.mean(np.square(data_val_DMAE1 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mae_val += [np.mean(np.abs(data_val_DMAE1 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mse_test += [np.mean(np.square(data_test_DMAE1 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "    mae_test += [np.mean(np.abs(data_test_DMAE1 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "    NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "    NMAE_train  = round(100*mae_train[-1],2)\n",
        "    NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "    NMAE_val  = round(100*mae_val[-1],2)\n",
        "    NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "    NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "    if mse_val[-1] == np.min(mse_val):\n",
        "        torch.save(dmae1.state_dict(), 'DMAE1_'+DATA_NUM+'_'+MISS_NUM+'.pt')\n",
        "\n",
        "    if epoch == 0 or (epoch+1) % 100 == 0:\n",
        "        print(\"epoch: {}\".format(epoch+1).ljust(15), end=\"\")\n",
        "        print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "        print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "        print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "        print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KQiYbDbjlF-8",
        "outputId": "04b83df2-c09e-4973-c229-dc3bd25b5015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1       NRMSE_train: 54.68%      NMAE_train: 45.74%       NRMSE_val: 54.56%        NMAE_val: 46.27%         NRMSE_test: 53.38%       NMAE_test: 44.98%        \n",
            "epoch: 100     NRMSE_train: 9.47%       NMAE_train: 6.86%        NRMSE_val: 8.93%         NMAE_val: 6.68%          NRMSE_test: 8.71%        NMAE_test: 6.5%          \n",
            "epoch: 200     NRMSE_train: 6.67%       NMAE_train: 4.82%        NRMSE_val: 4.84%         NMAE_val: 3.7%           NRMSE_test: 6.83%        NMAE_test: 4.59%         \n",
            "epoch: 300     NRMSE_train: 6.58%       NMAE_train: 4.76%        NRMSE_val: 4.69%         NMAE_val: 3.55%          NRMSE_test: 6.82%        NMAE_test: 4.61%         \n",
            "epoch: 400     NRMSE_train: 6.52%       NMAE_train: 4.69%        NRMSE_val: 4.63%         NMAE_val: 3.46%          NRMSE_test: 6.81%        NMAE_test: 4.56%         \n",
            "epoch: 500     NRMSE_train: 6.47%       NMAE_train: 4.65%        NRMSE_val: 4.63%         NMAE_val: 3.45%          NRMSE_test: 6.82%        NMAE_test: 4.57%         \n",
            "epoch: 600     NRMSE_train: 6.43%       NMAE_train: 4.62%        NRMSE_val: 4.63%         NMAE_val: 3.45%          NRMSE_test: 6.83%        NMAE_test: 4.58%         \n",
            "epoch: 700     NRMSE_train: 6.38%       NMAE_train: 4.59%        NRMSE_val: 4.69%         NMAE_val: 3.48%          NRMSE_test: 6.9%         NMAE_test: 4.67%         \n",
            "epoch: 800     NRMSE_train: 6.36%       NMAE_train: 4.57%        NRMSE_val: 4.67%         NMAE_val: 3.49%          NRMSE_test: 6.8%         NMAE_test: 4.57%         \n",
            "epoch: 900     NRMSE_train: 6.33%       NMAE_train: 4.56%        NRMSE_val: 4.69%         NMAE_val: 3.49%          NRMSE_test: 6.8%         NMAE_test: 4.59%         \n",
            "epoch: 1000    NRMSE_train: 6.29%       NMAE_train: 4.52%        NRMSE_val: 4.71%         NMAE_val: 3.52%          NRMSE_test: 6.8%         NMAE_test: 4.59%         \n",
            "epoch: 1100    NRMSE_train: 6.38%       NMAE_train: 4.61%        NRMSE_val: 4.72%         NMAE_val: 3.58%          NRMSE_test: 6.69%        NMAE_test: 4.48%         \n",
            "epoch: 1200    NRMSE_train: 6.22%       NMAE_train: 4.49%        NRMSE_val: 4.66%         NMAE_val: 3.51%          NRMSE_test: 6.67%        NMAE_test: 4.5%          \n",
            "epoch: 1300    NRMSE_train: 6.08%       NMAE_train: 4.5%         NRMSE_val: 4.71%         NMAE_val: 3.58%          NRMSE_test: 6.25%        NMAE_test: 4.32%         \n",
            "epoch: 1400    NRMSE_train: 5.24%       NMAE_train: 4.02%        NRMSE_val: 4.66%         NMAE_val: 3.56%          NRMSE_test: 5.25%        NMAE_test: 3.86%         \n",
            "epoch: 1500    NRMSE_train: 4.68%       NMAE_train: 3.54%        NRMSE_val: 4.32%         NMAE_val: 3.27%          NRMSE_test: 4.98%        NMAE_test: 3.67%         \n",
            "epoch: 1600    NRMSE_train: 4.61%       NMAE_train: 3.52%        NRMSE_val: 4.34%         NMAE_val: 3.32%          NRMSE_test: 4.96%        NMAE_test: 3.64%         \n",
            "epoch: 1700    NRMSE_train: 4.48%       NMAE_train: 3.45%        NRMSE_val: 4.35%         NMAE_val: 3.34%          NRMSE_test: 4.97%        NMAE_test: 3.66%         \n",
            "epoch: 1800    NRMSE_train: 4.3%        NMAE_train: 3.3%         NRMSE_val: 4.21%         NMAE_val: 3.25%          NRMSE_test: 4.87%        NMAE_test: 3.64%         \n",
            "epoch: 1900    NRMSE_train: 4.21%       NMAE_train: 3.23%        NRMSE_val: 4.13%         NMAE_val: 3.2%           NRMSE_test: 4.86%        NMAE_test: 3.67%         \n",
            "epoch: 2000    NRMSE_train: 4.17%       NMAE_train: 3.19%        NRMSE_val: 4.07%         NMAE_val: 3.18%          NRMSE_test: 4.79%        NMAE_test: 3.65%         \n",
            "epoch: 2100    NRMSE_train: 4.17%       NMAE_train: 3.22%        NRMSE_val: 4.08%         NMAE_val: 3.19%          NRMSE_test: 4.7%         NMAE_test: 3.57%         \n",
            "epoch: 2200    NRMSE_train: 4.1%        NMAE_train: 3.16%        NRMSE_val: 3.96%         NMAE_val: 3.1%           NRMSE_test: 4.66%        NMAE_test: 3.55%         \n",
            "epoch: 2300    NRMSE_train: 4.07%       NMAE_train: 3.13%        NRMSE_val: 3.94%         NMAE_val: 3.1%           NRMSE_test: 4.59%        NMAE_test: 3.52%         \n",
            "epoch: 2400    NRMSE_train: 4.03%       NMAE_train: 3.11%        NRMSE_val: 3.87%         NMAE_val: 3.04%          NRMSE_test: 4.52%        NMAE_test: 3.45%         \n",
            "epoch: 2500    NRMSE_train: 4.03%       NMAE_train: 3.13%        NRMSE_val: 3.84%         NMAE_val: 3.03%          NRMSE_test: 4.48%        NMAE_test: 3.4%          \n",
            "epoch: 2600    NRMSE_train: 3.94%       NMAE_train: 3.02%        NRMSE_val: 3.73%         NMAE_val: 2.93%          NRMSE_test: 4.48%        NMAE_test: 3.42%         \n",
            "epoch: 2700    NRMSE_train: 3.95%       NMAE_train: 3.04%        NRMSE_val: 3.71%         NMAE_val: 2.92%          NRMSE_test: 4.47%        NMAE_test: 3.38%         \n",
            "epoch: 2800    NRMSE_train: 3.87%       NMAE_train: 2.96%        NRMSE_val: 3.61%         NMAE_val: 2.82%          NRMSE_test: 4.44%        NMAE_test: 3.35%         \n",
            "epoch: 2900    NRMSE_train: 3.85%       NMAE_train: 2.92%        NRMSE_val: 3.57%         NMAE_val: 2.78%          NRMSE_test: 4.44%        NMAE_test: 3.36%         \n",
            "epoch: 3000    NRMSE_train: 3.86%       NMAE_train: 2.96%        NRMSE_val: 3.55%         NMAE_val: 2.79%          NRMSE_test: 4.41%        NMAE_test: 3.3%          \n",
            "epoch: 3100    NRMSE_train: 3.84%       NMAE_train: 2.93%        NRMSE_val: 3.5%          NMAE_val: 2.75%          NRMSE_test: 4.39%        NMAE_test: 3.29%         \n",
            "epoch: 3200    NRMSE_train: 3.79%       NMAE_train: 2.89%        NRMSE_val: 3.44%         NMAE_val: 2.69%          NRMSE_test: 4.4%         NMAE_test: 3.28%         \n",
            "epoch: 3300    NRMSE_train: 3.77%       NMAE_train: 2.86%        NRMSE_val: 3.47%         NMAE_val: 2.69%          NRMSE_test: 4.45%        NMAE_test: 3.33%         \n",
            "epoch: 3400    NRMSE_train: 3.81%       NMAE_train: 2.92%        NRMSE_val: 3.45%         NMAE_val: 2.72%          NRMSE_test: 4.44%        NMAE_test: 3.31%         \n",
            "epoch: 3500    NRMSE_train: 3.74%       NMAE_train: 2.86%        NRMSE_val: 3.4%          NMAE_val: 2.64%          NRMSE_test: 4.45%        NMAE_test: 3.33%         \n",
            "epoch: 3600    NRMSE_train: 3.72%       NMAE_train: 2.84%        NRMSE_val: 3.4%          NMAE_val: 2.62%          NRMSE_test: 4.48%        NMAE_test: 3.33%         \n",
            "epoch: 3700    NRMSE_train: 3.75%       NMAE_train: 2.84%        NRMSE_val: 3.46%         NMAE_val: 2.61%          NRMSE_test: 4.52%        NMAE_test: 3.36%         \n",
            "epoch: 3800    NRMSE_train: 3.73%       NMAE_train: 2.87%        NRMSE_val: 3.39%         NMAE_val: 2.65%          NRMSE_test: 4.43%        NMAE_test: 3.27%         \n",
            "epoch: 3900    NRMSE_train: 3.67%       NMAE_train: 2.79%        NRMSE_val: 3.37%         NMAE_val: 2.59%          NRMSE_test: 4.47%        NMAE_test: 3.32%         \n",
            "epoch: 4000    NRMSE_train: 3.65%       NMAE_train: 2.77%        NRMSE_val: 3.37%         NMAE_val: 2.58%          NRMSE_test: 4.42%        NMAE_test: 3.27%         \n",
            "epoch: 4100    NRMSE_train: 3.67%       NMAE_train: 2.81%        NRMSE_val: 3.38%         NMAE_val: 2.62%          NRMSE_test: 4.36%        NMAE_test: 3.21%         \n",
            "epoch: 4200    NRMSE_train: 3.65%       NMAE_train: 2.78%        NRMSE_val: 3.36%         NMAE_val: 2.6%           NRMSE_test: 4.39%        NMAE_test: 3.23%         \n",
            "epoch: 4300    NRMSE_train: 3.63%       NMAE_train: 2.77%        NRMSE_val: 3.34%         NMAE_val: 2.55%          NRMSE_test: 4.42%        NMAE_test: 3.25%         \n",
            "epoch: 4400    NRMSE_train: 3.62%       NMAE_train: 2.74%        NRMSE_val: 3.37%         NMAE_val: 2.57%          NRMSE_test: 4.42%        NMAE_test: 3.25%         \n",
            "epoch: 4500    NRMSE_train: 3.62%       NMAE_train: 2.77%        NRMSE_val: 3.36%         NMAE_val: 2.6%           NRMSE_test: 4.37%        NMAE_test: 3.21%         \n",
            "epoch: 4600    NRMSE_train: 3.6%        NMAE_train: 2.72%        NRMSE_val: 3.37%         NMAE_val: 2.52%          NRMSE_test: 4.45%        NMAE_test: 3.26%         \n",
            "epoch: 4700    NRMSE_train: 3.6%        NMAE_train: 2.72%        NRMSE_val: 3.34%         NMAE_val: 2.51%          NRMSE_test: 4.4%         NMAE_test: 3.22%         \n",
            "epoch: 4800    NRMSE_train: 3.58%       NMAE_train: 2.71%        NRMSE_val: 3.36%         NMAE_val: 2.56%          NRMSE_test: 4.43%        NMAE_test: 3.26%         \n",
            "epoch: 4900    NRMSE_train: 3.58%       NMAE_train: 2.71%        NRMSE_val: 3.34%         NMAE_val: 2.51%          NRMSE_test: 4.39%        NMAE_test: 3.2%          \n",
            "epoch: 5000    NRMSE_train: 3.59%       NMAE_train: 2.75%        NRMSE_val: 3.34%         NMAE_val: 2.57%          NRMSE_test: 4.35%        NMAE_test: 3.17%         \n",
            "epoch: 5100    NRMSE_train: 3.56%       NMAE_train: 2.7%         NRMSE_val: 3.33%         NMAE_val: 2.53%          NRMSE_test: 4.36%        NMAE_test: 3.18%         \n",
            "epoch: 5200    NRMSE_train: 3.56%       NMAE_train: 2.71%        NRMSE_val: 3.33%         NMAE_val: 2.53%          NRMSE_test: 4.35%        NMAE_test: 3.17%         \n",
            "epoch: 5300    NRMSE_train: 3.57%       NMAE_train: 2.68%        NRMSE_val: 3.38%         NMAE_val: 2.51%          NRMSE_test: 4.41%        NMAE_test: 3.21%         \n",
            "epoch: 5400    NRMSE_train: 3.55%       NMAE_train: 2.68%        NRMSE_val: 3.38%         NMAE_val: 2.55%          NRMSE_test: 4.42%        NMAE_test: 3.21%         \n",
            "epoch: 5500    NRMSE_train: 3.53%       NMAE_train: 2.67%        NRMSE_val: 3.37%         NMAE_val: 2.56%          NRMSE_test: 4.41%        NMAE_test: 3.22%         \n",
            "epoch: 5600    NRMSE_train: 3.54%       NMAE_train: 2.69%        NRMSE_val: 3.35%         NMAE_val: 2.55%          NRMSE_test: 4.36%        NMAE_test: 3.18%         \n",
            "epoch: 5700    NRMSE_train: 3.53%       NMAE_train: 2.66%        NRMSE_val: 3.34%         NMAE_val: 2.54%          NRMSE_test: 4.35%        NMAE_test: 3.15%         \n",
            "epoch: 5800    NRMSE_train: 3.52%       NMAE_train: 2.65%        NRMSE_val: 3.34%         NMAE_val: 2.52%          NRMSE_test: 4.41%        NMAE_test: 3.2%          \n",
            "epoch: 5900    NRMSE_train: 3.52%       NMAE_train: 2.66%        NRMSE_val: 3.34%         NMAE_val: 2.51%          NRMSE_test: 4.37%        NMAE_test: 3.16%         \n",
            "epoch: 6000    NRMSE_train: 3.55%       NMAE_train: 2.71%        NRMSE_val: 3.38%         NMAE_val: 2.62%          NRMSE_test: 4.33%        NMAE_test: 3.14%         \n",
            "epoch: 6100    NRMSE_train: 3.52%       NMAE_train: 2.67%        NRMSE_val: 3.31%         NMAE_val: 2.53%          NRMSE_test: 4.32%        NMAE_test: 3.11%         \n",
            "epoch: 6200    NRMSE_train: 3.52%       NMAE_train: 2.68%        NRMSE_val: 3.31%         NMAE_val: 2.53%          NRMSE_test: 4.32%        NMAE_test: 3.11%         \n",
            "epoch: 6300    NRMSE_train: 3.51%       NMAE_train: 2.64%        NRMSE_val: 3.34%         NMAE_val: 2.53%          NRMSE_test: 4.37%        NMAE_test: 3.16%         \n",
            "epoch: 6400    NRMSE_train: 3.51%       NMAE_train: 2.66%        NRMSE_val: 3.34%         NMAE_val: 2.57%          NRMSE_test: 4.32%        NMAE_test: 3.11%         \n",
            "epoch: 6500    NRMSE_train: 3.49%       NMAE_train: 2.64%        NRMSE_val: 3.35%         NMAE_val: 2.57%          NRMSE_test: 4.33%        NMAE_test: 3.12%         \n",
            "epoch: 6600    NRMSE_train: 3.49%       NMAE_train: 2.63%        NRMSE_val: 3.33%         NMAE_val: 2.54%          NRMSE_test: 4.33%        NMAE_test: 3.12%         \n",
            "epoch: 6700    NRMSE_train: 3.48%       NMAE_train: 2.61%        NRMSE_val: 3.37%         NMAE_val: 2.56%          NRMSE_test: 4.36%        NMAE_test: 3.15%         \n",
            "epoch: 6800    NRMSE_train: 3.47%       NMAE_train: 2.6%         NRMSE_val: 3.35%         NMAE_val: 2.55%          NRMSE_test: 4.36%        NMAE_test: 3.14%         \n",
            "epoch: 6900    NRMSE_train: 3.49%       NMAE_train: 2.63%        NRMSE_val: 3.36%         NMAE_val: 2.54%          NRMSE_test: 4.39%        NMAE_test: 3.17%         \n",
            "epoch: 7000    NRMSE_train: 3.48%       NMAE_train: 2.64%        NRMSE_val: 3.3%          NMAE_val: 2.54%          NRMSE_test: 4.32%        NMAE_test: 3.1%          \n",
            "epoch: 7100    NRMSE_train: 3.47%       NMAE_train: 2.61%        NRMSE_val: 3.33%         NMAE_val: 2.54%          NRMSE_test: 4.33%        NMAE_test: 3.12%         \n",
            "epoch: 7200    NRMSE_train: 3.46%       NMAE_train: 2.61%        NRMSE_val: 3.32%         NMAE_val: 2.53%          NRMSE_test: 4.36%        NMAE_test: 3.12%         \n",
            "epoch: 7300    NRMSE_train: 3.47%       NMAE_train: 2.6%         NRMSE_val: 3.35%         NMAE_val: 2.55%          NRMSE_test: 4.37%        NMAE_test: 3.14%         \n",
            "epoch: 7400    NRMSE_train: 3.46%       NMAE_train: 2.62%        NRMSE_val: 3.33%         NMAE_val: 2.56%          NRMSE_test: 4.32%        NMAE_test: 3.11%         \n",
            "epoch: 7500    NRMSE_train: 3.47%       NMAE_train: 2.64%        NRMSE_val: 3.33%         NMAE_val: 2.57%          NRMSE_test: 4.31%        NMAE_test: 3.09%         \n",
            "epoch: 7600    NRMSE_train: 3.49%       NMAE_train: 2.65%        NRMSE_val: 3.32%         NMAE_val: 2.57%          NRMSE_test: 4.31%        NMAE_test: 3.07%         \n",
            "epoch: 7700    NRMSE_train: 3.44%       NMAE_train: 2.59%        NRMSE_val: 3.31%         NMAE_val: 2.53%          NRMSE_test: 4.34%        NMAE_test: 3.11%         \n",
            "epoch: 7800    NRMSE_train: 3.47%       NMAE_train: 2.63%        NRMSE_val: 3.33%         NMAE_val: 2.58%          NRMSE_test: 4.29%        NMAE_test: 3.07%         \n",
            "epoch: 7900    NRMSE_train: 3.48%       NMAE_train: 2.63%        NRMSE_val: 3.29%         NMAE_val: 2.54%          NRMSE_test: 4.28%        NMAE_test: 3.06%         \n",
            "epoch: 8000    NRMSE_train: 3.45%       NMAE_train: 2.6%         NRMSE_val: 3.3%          NMAE_val: 2.54%          NRMSE_test: 4.25%        NMAE_test: 3.06%         \n",
            "epoch: 8100    NRMSE_train: 3.47%       NMAE_train: 2.62%        NRMSE_val: 3.27%         NMAE_val: 2.52%          NRMSE_test: 4.23%        NMAE_test: 3.04%         \n",
            "epoch: 8200    NRMSE_train: 3.47%       NMAE_train: 2.61%        NRMSE_val: 3.29%         NMAE_val: 2.55%          NRMSE_test: 4.23%        NMAE_test: 3.04%         \n",
            "epoch: 8300    NRMSE_train: 3.49%       NMAE_train: 2.63%        NRMSE_val: 3.29%         NMAE_val: 2.54%          NRMSE_test: 4.23%        NMAE_test: 3.03%         \n",
            "epoch: 8400    NRMSE_train: 3.42%       NMAE_train: 2.56%        NRMSE_val: 3.3%          NMAE_val: 2.52%          NRMSE_test: 4.32%        NMAE_test: 3.1%          \n",
            "epoch: 8500    NRMSE_train: 3.44%       NMAE_train: 2.59%        NRMSE_val: 3.24%         NMAE_val: 2.5%           NRMSE_test: 4.19%        NMAE_test: 2.99%         \n",
            "epoch: 8600    NRMSE_train: 3.45%       NMAE_train: 2.6%         NRMSE_val: 3.33%         NMAE_val: 2.59%          NRMSE_test: 4.25%        NMAE_test: 3.04%         \n",
            "epoch: 8700    NRMSE_train: 3.44%       NMAE_train: 2.59%        NRMSE_val: 3.29%         NMAE_val: 2.55%          NRMSE_test: 4.2%         NMAE_test: 3.0%          \n",
            "epoch: 8800    NRMSE_train: 3.41%       NMAE_train: 2.57%        NRMSE_val: 3.28%         NMAE_val: 2.54%          NRMSE_test: 4.22%        NMAE_test: 3.02%         \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-9211664e17c3>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_miss2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_miss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoising Masked AutoEncoder (Test)\n",
        "\n",
        "batch_size = 128\n",
        "total_batch = int(len(data_train_miss)/batch_size) + 1\n",
        "\n",
        "dmae1 = AED()\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "\n",
        "dmae1.load_state_dict(torch.load('DMAE1_'+DATA_NUM+'_'+MISS_NUM+'.pt'))\n",
        "\n",
        "data_train_DMAE1 = dmae1.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_val_DMAE1   = dmae1.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_test_DMAE1  = dmae1.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "data_train_DMAE1[data_train_miss - data_train_miss2 == 0] = 0\n",
        "data_val_DMAE1[data_val_miss - data_val_miss2 == 0] = 0\n",
        "data_test_DMAE1[data_test_miss != 0] = 0\n",
        "\n",
        "mse_train += [np.mean(np.square(data_train_DMAE1 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mae_train += [np.mean(np.abs(data_train_DMAE1 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mse_val += [np.mean(np.square(data_val_DMAE1 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mae_val += [np.mean(np.abs(data_val_DMAE1 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mse_test += [np.mean(np.square(data_test_DMAE1 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "mae_test += [np.mean(np.abs(data_test_DMAE1 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "NMAE_train  = round(100*mae_train[-1],2)\n",
        "NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "NMAE_val  = round(100*mae_val[-1],2)\n",
        "NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "id": "aovr5KLzmFHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3764db9d-e812-4e47-936d-979996f3c0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRMSE_train: 3.43%       NMAE_train: 2.58%        NRMSE_val: 3.2%          NMAE_val: 2.44%          NRMSE_test: 4.21%        NMAE_test: 2.99%         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoising Masked AutoEncoder 2 (Training)\n",
        "\n",
        "batch_size1 = 128\n",
        "total_batch1 = int(len(data_train_miss)/batch_size1) + 1\n",
        "batch_size2 = 32\n",
        "total_batch2 = int(len(data_val_miss)/batch_size2) + 1\n",
        "\n",
        "dmae2 = AED()\n",
        "optimizer = optim.Adam(dmae2.parameters(), lr = 0.001)\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "for epoch in range(10000):\n",
        "    for i in range(total_batch1):\n",
        "        batch_x = torch.tensor(data_train_miss2[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch_y = torch.tensor(data_train_miss2[batch_size1*i:batch_size1*(i+1),:] ,dtype=torch.float)\n",
        "        batch = [batch_x, batch_y]\n",
        "        train_MAE(dmae2, batch, optimizer)\n",
        "\n",
        "    data_train_DMAE2 = dmae2.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_val_DMAE2   = dmae2.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "    data_test_DMAE2  = dmae2.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "    data_train_DMAE2[data_train_miss - data_train_miss2 == 0] = 0\n",
        "    data_val_DMAE2[data_val_miss - data_val_miss2 == 0] = 0\n",
        "    data_test_DMAE2[data_test_miss != 0] = 0\n",
        "\n",
        "    mse_train += [np.mean(np.square(data_train_DMAE2 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mae_train += [np.mean(np.abs(data_train_DMAE2 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "    mse_val += [np.mean(np.square(data_val_DMAE2 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mae_val += [np.mean(np.abs(data_val_DMAE2 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "    mse_test += [np.mean(np.square(data_test_DMAE2 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "    mae_test += [np.mean(np.abs(data_test_DMAE2 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "    NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "    NMAE_train  = round(100*mae_train[-1],2)\n",
        "    NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "    NMAE_val  = round(100*mae_val[-1],2)\n",
        "    NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "    NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "    if mse_val[-1] == np.min(mse_val):\n",
        "        torch.save(dmae2.state_dict(), 'DMAE2_'+DATA_NUM+'_'+MISS_NUM+'.pt')\n",
        "\n",
        "    if epoch == 0 or (epoch+1) % 100 == 0:\n",
        "        print(\"epoch: {}\".format(epoch+1).ljust(15), end=\"\")\n",
        "        print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "        print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "        print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "        print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "        print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ED8_LY81g30G",
        "outputId": "b77af4cd-9bd8-42bf-efc9-219f636ddfc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1       NRMSE_train: 54.75%      NMAE_train: 47.42%       NRMSE_val: 53.82%        NMAE_val: 46.64%         NRMSE_test: 54.13%       NMAE_test: 46.97%        \n",
            "epoch: 100     NRMSE_train: 8.83%       NMAE_train: 6.4%         NRMSE_val: 8.08%         NMAE_val: 6.09%          NRMSE_test: 8.12%        NMAE_test: 6.05%         \n",
            "epoch: 200     NRMSE_train: 6.77%       NMAE_train: 4.89%        NRMSE_val: 4.9%          NMAE_val: 3.73%          NRMSE_test: 6.77%        NMAE_test: 4.53%         \n",
            "epoch: 300     NRMSE_train: 6.73%       NMAE_train: 4.86%        NRMSE_val: 4.7%          NMAE_val: 3.54%          NRMSE_test: 6.78%        NMAE_test: 4.52%         \n",
            "epoch: 400     NRMSE_train: 6.64%       NMAE_train: 4.77%        NRMSE_val: 4.66%         NMAE_val: 3.48%          NRMSE_test: 6.83%        NMAE_test: 4.58%         \n",
            "epoch: 500     NRMSE_train: 6.62%       NMAE_train: 4.76%        NRMSE_val: 4.64%         NMAE_val: 3.45%          NRMSE_test: 6.83%        NMAE_test: 4.59%         \n",
            "epoch: 600     NRMSE_train: 6.56%       NMAE_train: 4.73%        NRMSE_val: 4.66%         NMAE_val: 3.46%          NRMSE_test: 6.87%        NMAE_test: 4.64%         \n",
            "epoch: 700     NRMSE_train: 6.53%       NMAE_train: 4.7%         NRMSE_val: 4.67%         NMAE_val: 3.46%          NRMSE_test: 6.87%        NMAE_test: 4.65%         \n",
            "epoch: 800     NRMSE_train: 6.52%       NMAE_train: 4.71%        NRMSE_val: 4.7%          NMAE_val: 3.48%          NRMSE_test: 6.86%        NMAE_test: 4.64%         \n",
            "epoch: 900     NRMSE_train: 6.49%       NMAE_train: 4.69%        NRMSE_val: 4.69%         NMAE_val: 3.51%          NRMSE_test: 6.77%        NMAE_test: 4.57%         \n",
            "epoch: 1000    NRMSE_train: 6.4%        NMAE_train: 4.69%        NRMSE_val: 4.78%         NMAE_val: 3.61%          NRMSE_test: 6.53%        NMAE_test: 4.46%         \n",
            "epoch: 1100    NRMSE_train: 5.97%       NMAE_train: 4.49%        NRMSE_val: 5.19%         NMAE_val: 3.85%          NRMSE_test: 5.77%        NMAE_test: 4.19%         \n",
            "epoch: 1200    NRMSE_train: 5.09%       NMAE_train: 3.85%        NRMSE_val: 4.89%         NMAE_val: 3.56%          NRMSE_test: 5.12%        NMAE_test: 3.79%         \n",
            "epoch: 1300    NRMSE_train: 4.72%       NMAE_train: 3.58%        NRMSE_val: 4.61%         NMAE_val: 3.35%          NRMSE_test: 4.92%        NMAE_test: 3.66%         \n",
            "epoch: 1400    NRMSE_train: 4.52%       NMAE_train: 3.41%        NRMSE_val: 4.38%         NMAE_val: 3.2%           NRMSE_test: 4.8%         NMAE_test: 3.6%          \n",
            "epoch: 1500    NRMSE_train: 4.43%       NMAE_train: 3.34%        NRMSE_val: 4.2%          NMAE_val: 3.15%          NRMSE_test: 4.74%        NMAE_test: 3.57%         \n",
            "epoch: 1600    NRMSE_train: 4.33%       NMAE_train: 3.27%        NRMSE_val: 4.11%         NMAE_val: 3.12%          NRMSE_test: 4.64%        NMAE_test: 3.51%         \n",
            "epoch: 1700    NRMSE_train: 4.29%       NMAE_train: 3.25%        NRMSE_val: 4.05%         NMAE_val: 3.11%          NRMSE_test: 4.58%        NMAE_test: 3.46%         \n",
            "epoch: 1800    NRMSE_train: 4.23%       NMAE_train: 3.2%         NRMSE_val: 3.97%         NMAE_val: 3.04%          NRMSE_test: 4.64%        NMAE_test: 3.55%         \n",
            "epoch: 1900    NRMSE_train: 4.2%        NMAE_train: 3.19%        NRMSE_val: 3.9%          NMAE_val: 3.03%          NRMSE_test: 4.58%        NMAE_test: 3.48%         \n",
            "epoch: 2000    NRMSE_train: 4.15%       NMAE_train: 3.16%        NRMSE_val: 3.86%         NMAE_val: 3.0%           NRMSE_test: 4.57%        NMAE_test: 3.48%         \n",
            "epoch: 2100    NRMSE_train: 4.17%       NMAE_train: 3.21%        NRMSE_val: 3.85%         NMAE_val: 2.98%          NRMSE_test: 4.52%        NMAE_test: 3.41%         \n",
            "epoch: 2200    NRMSE_train: 4.16%       NMAE_train: 3.19%        NRMSE_val: 3.83%         NMAE_val: 2.98%          NRMSE_test: 4.57%        NMAE_test: 3.45%         \n",
            "epoch: 2300    NRMSE_train: 4.11%       NMAE_train: 3.13%        NRMSE_val: 3.84%         NMAE_val: 2.94%          NRMSE_test: 4.58%        NMAE_test: 3.49%         \n",
            "epoch: 2400    NRMSE_train: 4.07%       NMAE_train: 3.11%        NRMSE_val: 3.78%         NMAE_val: 2.95%          NRMSE_test: 4.51%        NMAE_test: 3.42%         \n",
            "epoch: 2500    NRMSE_train: 4.05%       NMAE_train: 3.08%        NRMSE_val: 3.77%         NMAE_val: 2.9%           NRMSE_test: 4.56%        NMAE_test: 3.48%         \n",
            "epoch: 2600    NRMSE_train: 4.1%        NMAE_train: 3.17%        NRMSE_val: 3.78%         NMAE_val: 2.98%          NRMSE_test: 4.48%        NMAE_test: 3.37%         \n",
            "epoch: 2700    NRMSE_train: 4.04%       NMAE_train: 3.1%         NRMSE_val: 3.73%         NMAE_val: 2.93%          NRMSE_test: 4.51%        NMAE_test: 3.41%         \n",
            "epoch: 2800    NRMSE_train: 3.99%       NMAE_train: 3.05%        NRMSE_val: 3.63%         NMAE_val: 2.84%          NRMSE_test: 4.52%        NMAE_test: 3.41%         \n",
            "epoch: 2900    NRMSE_train: 3.98%       NMAE_train: 3.05%        NRMSE_val: 3.57%         NMAE_val: 2.81%          NRMSE_test: 4.51%        NMAE_test: 3.37%         \n",
            "epoch: 3000    NRMSE_train: 3.94%       NMAE_train: 3.04%        NRMSE_val: 3.52%         NMAE_val: 2.75%          NRMSE_test: 4.46%        NMAE_test: 3.31%         \n",
            "epoch: 3100    NRMSE_train: 3.87%       NMAE_train: 2.96%        NRMSE_val: 3.47%         NMAE_val: 2.67%          NRMSE_test: 4.48%        NMAE_test: 3.29%         \n",
            "epoch: 3200    NRMSE_train: 3.89%       NMAE_train: 2.99%        NRMSE_val: 3.44%         NMAE_val: 2.67%          NRMSE_test: 4.44%        NMAE_test: 3.25%         \n",
            "epoch: 3300    NRMSE_train: 3.84%       NMAE_train: 2.95%        NRMSE_val: 3.42%         NMAE_val: 2.63%          NRMSE_test: 4.43%        NMAE_test: 3.24%         \n",
            "epoch: 3400    NRMSE_train: 3.81%       NMAE_train: 2.93%        NRMSE_val: 3.4%          NMAE_val: 2.57%          NRMSE_test: 4.45%        NMAE_test: 3.23%         \n",
            "epoch: 3500    NRMSE_train: 3.78%       NMAE_train: 2.89%        NRMSE_val: 3.4%          NMAE_val: 2.58%          NRMSE_test: 4.44%        NMAE_test: 3.25%         \n",
            "epoch: 3600    NRMSE_train: 3.78%       NMAE_train: 2.87%        NRMSE_val: 3.4%          NMAE_val: 2.55%          NRMSE_test: 4.44%        NMAE_test: 3.25%         \n",
            "epoch: 3700    NRMSE_train: 3.79%       NMAE_train: 2.91%        NRMSE_val: 3.39%         NMAE_val: 2.59%          NRMSE_test: 4.4%         NMAE_test: 3.19%         \n",
            "epoch: 3800    NRMSE_train: 3.77%       NMAE_train: 2.88%        NRMSE_val: 3.38%         NMAE_val: 2.57%          NRMSE_test: 4.37%        NMAE_test: 3.19%         \n",
            "epoch: 3900    NRMSE_train: 3.75%       NMAE_train: 2.86%        NRMSE_val: 3.37%         NMAE_val: 2.53%          NRMSE_test: 4.38%        NMAE_test: 3.18%         \n",
            "epoch: 4000    NRMSE_train: 3.76%       NMAE_train: 2.86%        NRMSE_val: 3.38%         NMAE_val: 2.52%          NRMSE_test: 4.41%        NMAE_test: 3.21%         \n",
            "epoch: 4100    NRMSE_train: 3.75%       NMAE_train: 2.88%        NRMSE_val: 3.36%         NMAE_val: 2.54%          NRMSE_test: 4.34%        NMAE_test: 3.15%         \n",
            "epoch: 4200    NRMSE_train: 3.72%       NMAE_train: 2.83%        NRMSE_val: 3.36%         NMAE_val: 2.52%          NRMSE_test: 4.38%        NMAE_test: 3.18%         \n",
            "epoch: 4300    NRMSE_train: 3.75%       NMAE_train: 2.84%        NRMSE_val: 3.39%         NMAE_val: 2.53%          NRMSE_test: 4.35%        NMAE_test: 3.17%         \n",
            "epoch: 4400    NRMSE_train: 3.75%       NMAE_train: 2.87%        NRMSE_val: 3.35%         NMAE_val: 2.54%          NRMSE_test: 4.33%        NMAE_test: 3.12%         \n",
            "epoch: 4500    NRMSE_train: 3.73%       NMAE_train: 2.85%        NRMSE_val: 3.34%         NMAE_val: 2.53%          NRMSE_test: 4.32%        NMAE_test: 3.14%         \n",
            "epoch: 4600    NRMSE_train: 3.72%       NMAE_train: 2.82%        NRMSE_val: 3.34%         NMAE_val: 2.52%          NRMSE_test: 4.32%        NMAE_test: 3.13%         \n",
            "epoch: 4700    NRMSE_train: 3.72%       NMAE_train: 2.83%        NRMSE_val: 3.33%         NMAE_val: 2.52%          NRMSE_test: 4.3%         NMAE_test: 3.13%         \n",
            "epoch: 4800    NRMSE_train: 3.74%       NMAE_train: 2.87%        NRMSE_val: 3.34%         NMAE_val: 2.55%          NRMSE_test: 4.29%        NMAE_test: 3.1%          \n",
            "epoch: 4900    NRMSE_train: 3.72%       NMAE_train: 2.83%        NRMSE_val: 3.3%          NMAE_val: 2.48%          NRMSE_test: 4.3%         NMAE_test: 3.11%         \n",
            "epoch: 5000    NRMSE_train: 3.73%       NMAE_train: 2.83%        NRMSE_val: 3.32%         NMAE_val: 2.51%          NRMSE_test: 4.33%        NMAE_test: 3.14%         \n",
            "epoch: 5100    NRMSE_train: 3.73%       NMAE_train: 2.85%        NRMSE_val: 3.33%         NMAE_val: 2.54%          NRMSE_test: 4.33%        NMAE_test: 3.14%         \n",
            "epoch: 5200    NRMSE_train: 3.73%       NMAE_train: 2.85%        NRMSE_val: 3.3%          NMAE_val: 2.51%          NRMSE_test: 4.33%        NMAE_test: 3.13%         \n",
            "epoch: 5300    NRMSE_train: 3.71%       NMAE_train: 2.82%        NRMSE_val: 3.28%         NMAE_val: 2.49%          NRMSE_test: 4.32%        NMAE_test: 3.13%         \n",
            "epoch: 5400    NRMSE_train: 3.73%       NMAE_train: 2.85%        NRMSE_val: 3.3%          NMAE_val: 2.52%          NRMSE_test: 4.34%        NMAE_test: 3.12%         \n",
            "epoch: 5500    NRMSE_train: 3.72%       NMAE_train: 2.83%        NRMSE_val: 3.3%          NMAE_val: 2.51%          NRMSE_test: 4.34%        NMAE_test: 3.14%         \n",
            "epoch: 5600    NRMSE_train: 3.69%       NMAE_train: 2.78%        NRMSE_val: 3.29%         NMAE_val: 2.48%          NRMSE_test: 4.35%        NMAE_test: 3.17%         \n",
            "epoch: 5700    NRMSE_train: 3.74%       NMAE_train: 2.84%        NRMSE_val: 3.31%         NMAE_val: 2.54%          NRMSE_test: 4.35%        NMAE_test: 3.13%         \n",
            "epoch: 5800    NRMSE_train: 3.7%        NMAE_train: 2.8%         NRMSE_val: 3.3%          NMAE_val: 2.51%          NRMSE_test: 4.39%        NMAE_test: 3.17%         \n",
            "epoch: 5900    NRMSE_train: 3.7%        NMAE_train: 2.8%         NRMSE_val: 3.26%         NMAE_val: 2.48%          NRMSE_test: 4.38%        NMAE_test: 3.16%         \n",
            "epoch: 6000    NRMSE_train: 3.71%       NMAE_train: 2.81%        NRMSE_val: 3.27%         NMAE_val: 2.48%          NRMSE_test: 4.39%        NMAE_test: 3.15%         \n",
            "epoch: 6100    NRMSE_train: 3.71%       NMAE_train: 2.81%        NRMSE_val: 3.31%         NMAE_val: 2.54%          NRMSE_test: 4.39%        NMAE_test: 3.16%         \n",
            "epoch: 6200    NRMSE_train: 3.74%       NMAE_train: 2.83%        NRMSE_val: 3.32%         NMAE_val: 2.54%          NRMSE_test: 4.39%        NMAE_test: 3.16%         \n",
            "epoch: 6300    NRMSE_train: 3.74%       NMAE_train: 2.82%        NRMSE_val: 3.33%         NMAE_val: 2.56%          NRMSE_test: 4.41%        NMAE_test: 3.18%         \n",
            "epoch: 6400    NRMSE_train: 3.76%       NMAE_train: 2.85%        NRMSE_val: 3.34%         NMAE_val: 2.58%          NRMSE_test: 4.43%        NMAE_test: 3.2%          \n",
            "epoch: 6500    NRMSE_train: 3.82%       NMAE_train: 2.89%        NRMSE_val: 3.37%         NMAE_val: 2.6%           NRMSE_test: 4.4%         NMAE_test: 3.14%         \n",
            "epoch: 6600    NRMSE_train: 3.74%       NMAE_train: 2.83%        NRMSE_val: 3.34%         NMAE_val: 2.57%          NRMSE_test: 4.43%        NMAE_test: 3.18%         \n",
            "epoch: 6700    NRMSE_train: 3.71%       NMAE_train: 2.79%        NRMSE_val: 3.29%         NMAE_val: 2.52%          NRMSE_test: 4.4%         NMAE_test: 3.18%         \n",
            "epoch: 6800    NRMSE_train: 3.7%        NMAE_train: 2.78%        NRMSE_val: 3.26%         NMAE_val: 2.49%          NRMSE_test: 4.4%         NMAE_test: 3.18%         \n",
            "epoch: 6900    NRMSE_train: 3.73%       NMAE_train: 2.8%         NRMSE_val: 3.32%         NMAE_val: 2.56%          NRMSE_test: 4.39%        NMAE_test: 3.17%         \n",
            "epoch: 7000    NRMSE_train: 3.76%       NMAE_train: 2.83%        NRMSE_val: 3.34%         NMAE_val: 2.59%          NRMSE_test: 4.39%        NMAE_test: 3.16%         \n",
            "epoch: 7100    NRMSE_train: 3.72%       NMAE_train: 2.8%         NRMSE_val: 3.29%         NMAE_val: 2.52%          NRMSE_test: 4.38%        NMAE_test: 3.15%         \n",
            "epoch: 7200    NRMSE_train: 3.71%       NMAE_train: 2.79%        NRMSE_val: 3.31%         NMAE_val: 2.55%          NRMSE_test: 4.4%         NMAE_test: 3.19%         \n",
            "epoch: 7300    NRMSE_train: 3.75%       NMAE_train: 2.81%        NRMSE_val: 3.32%         NMAE_val: 2.56%          NRMSE_test: 4.39%        NMAE_test: 3.17%         \n",
            "epoch: 7400    NRMSE_train: 3.68%       NMAE_train: 2.77%        NRMSE_val: 3.31%         NMAE_val: 2.55%          NRMSE_test: 4.39%        NMAE_test: 3.21%         \n",
            "epoch: 7500    NRMSE_train: 3.68%       NMAE_train: 2.76%        NRMSE_val: 3.32%         NMAE_val: 2.57%          NRMSE_test: 4.38%        NMAE_test: 3.19%         \n",
            "epoch: 7600    NRMSE_train: 3.68%       NMAE_train: 2.77%        NRMSE_val: 3.31%         NMAE_val: 2.55%          NRMSE_test: 4.35%        NMAE_test: 3.17%         \n",
            "epoch: 7700    NRMSE_train: 3.69%       NMAE_train: 2.76%        NRMSE_val: 3.31%         NMAE_val: 2.56%          NRMSE_test: 4.35%        NMAE_test: 3.16%         \n",
            "epoch: 7800    NRMSE_train: 3.68%       NMAE_train: 2.75%        NRMSE_val: 3.3%          NMAE_val: 2.56%          NRMSE_test: 4.33%        NMAE_test: 3.16%         \n",
            "epoch: 7900    NRMSE_train: 3.67%       NMAE_train: 2.75%        NRMSE_val: 3.33%         NMAE_val: 2.58%          NRMSE_test: 4.3%         NMAE_test: 3.14%         \n",
            "epoch: 8000    NRMSE_train: 3.67%       NMAE_train: 2.75%        NRMSE_val: 3.26%         NMAE_val: 2.5%           NRMSE_test: 4.3%         NMAE_test: 3.13%         \n",
            "epoch: 8100    NRMSE_train: 3.65%       NMAE_train: 2.74%        NRMSE_val: 3.27%         NMAE_val: 2.51%          NRMSE_test: 4.21%        NMAE_test: 3.07%         \n",
            "epoch: 8200    NRMSE_train: 3.69%       NMAE_train: 2.78%        NRMSE_val: 3.29%         NMAE_val: 2.55%          NRMSE_test: 4.2%         NMAE_test: 3.05%         \n",
            "epoch: 8300    NRMSE_train: 3.66%       NMAE_train: 2.75%        NRMSE_val: 3.27%         NMAE_val: 2.51%          NRMSE_test: 4.23%        NMAE_test: 3.05%         \n",
            "epoch: 8400    NRMSE_train: 3.68%       NMAE_train: 2.77%        NRMSE_val: 3.27%         NMAE_val: 2.51%          NRMSE_test: 4.21%        NMAE_test: 3.01%         \n",
            "epoch: 8500    NRMSE_train: 3.71%       NMAE_train: 2.8%         NRMSE_val: 3.31%         NMAE_val: 2.57%          NRMSE_test: 4.17%        NMAE_test: 2.97%         \n",
            "epoch: 8600    NRMSE_train: 3.64%       NMAE_train: 2.73%        NRMSE_val: 3.3%          NMAE_val: 2.54%          NRMSE_test: 4.19%        NMAE_test: 3.01%         \n",
            "epoch: 8700    NRMSE_train: 3.69%       NMAE_train: 2.78%        NRMSE_val: 3.29%         NMAE_val: 2.53%          NRMSE_test: 4.19%        NMAE_test: 2.96%         \n",
            "epoch: 8800    NRMSE_train: 3.64%       NMAE_train: 2.73%        NRMSE_val: 3.3%          NMAE_val: 2.55%          NRMSE_test: 4.16%        NMAE_test: 2.99%         \n",
            "epoch: 8900    NRMSE_train: 3.68%       NMAE_train: 2.78%        NRMSE_val: 3.32%         NMAE_val: 2.56%          NRMSE_test: 4.15%        NMAE_test: 2.97%         \n",
            "epoch: 9000    NRMSE_train: 3.63%       NMAE_train: 2.73%        NRMSE_val: 3.24%         NMAE_val: 2.48%          NRMSE_test: 4.13%        NMAE_test: 2.95%         \n",
            "epoch: 9100    NRMSE_train: 3.69%       NMAE_train: 2.78%        NRMSE_val: 3.34%         NMAE_val: 2.59%          NRMSE_test: 4.18%        NMAE_test: 2.98%         \n",
            "epoch: 9200    NRMSE_train: 3.64%       NMAE_train: 2.73%        NRMSE_val: 3.3%          NMAE_val: 2.54%          NRMSE_test: 4.14%        NMAE_test: 2.98%         \n",
            "epoch: 9300    NRMSE_train: 3.66%       NMAE_train: 2.77%        NRMSE_val: 3.29%         NMAE_val: 2.52%          NRMSE_test: 4.11%        NMAE_test: 2.94%         \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3b22965985e0>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_miss2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_MAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmae2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdata_train_DMAE2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdmae2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_miss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a78d9776801b>\u001b[0m in \u001b[0;36mtrain_MAE\u001b[0;34m(model, batch, optimizer)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoising Masked AutoEncoder (Test)\n",
        "\n",
        "batch_size = 128\n",
        "total_batch = int(len(data_train_miss)/batch_size) + 1\n",
        "\n",
        "dmae2 = AED()\n",
        "\n",
        "mse_train = []; mse_val = []; mse_test = []\n",
        "mae_train = []; mae_val = []; mae_test = []\n",
        "\n",
        "dmae2.load_state_dict(torch.load('DMAE2_'+DATA_NUM+'_'+MISS_NUM+'.pt'))\n",
        "\n",
        "data_train_DMAE2 = dmae2.forward(torch.tensor(data_train_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_val_DMAE2   = dmae2.forward(torch.tensor(data_val_miss2, dtype=torch.float))[1].detach().numpy()\n",
        "data_test_DMAE2  = dmae2.forward(torch.tensor(data_test_miss, dtype=torch.float))[1].detach().numpy()\n",
        "\n",
        "data_train_DMAE2[data_train_miss - data_train_miss2 == 0] = 0\n",
        "data_val_DMAE2[data_val_miss - data_val_miss2 == 0] = 0\n",
        "data_test_DMAE2[data_test_miss != 0] = 0\n",
        "\n",
        "mse_train += [np.mean(np.square(data_train_DMAE2 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mae_train += [np.mean(np.abs(data_train_DMAE2 - (data_train_miss - data_train_miss2)))*mean_corrector_train]\n",
        "mse_val += [np.mean(np.square(data_val_DMAE2 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mae_val += [np.mean(np.abs(data_val_DMAE2 - (data_val_miss - data_val_miss2)))*mean_corrector_val]\n",
        "mse_test += [np.mean(np.square(data_test_DMAE2 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "mae_test += [np.mean(np.abs(data_test_DMAE2 - (data_test - data_test_miss)))*mean_corrector_test]\n",
        "\n",
        "NRMSE_train = round(100*np.sqrt(mse_train[-1]),2)\n",
        "NMAE_train  = round(100*mae_train[-1],2)\n",
        "NRMSE_val = round(100*np.sqrt(mse_val[-1]),2)\n",
        "NMAE_val  = round(100*mae_val[-1],2)\n",
        "NRMSE_test = round(100*np.sqrt(mse_test[-1]),2)\n",
        "NMAE_test  = round(100*mae_test[-1],2)\n",
        "\n",
        "print(\"NRMSE_train: {}%\".format(NRMSE_train).ljust(25), end=\"\")\n",
        "print(\"NMAE_train: {}%\".format(NMAE_train).ljust(25), end=\"\")\n",
        "print(\"NRMSE_val: {}%\".format(NRMSE_val).ljust(25), end=\"\")\n",
        "print(\"NMAE_val: {}%\".format(NMAE_val).ljust(25), end=\"\")\n",
        "print(\"NRMSE_test: {}%\".format(NRMSE_test).ljust(25), end=\"\")\n",
        "print(\"NMAE_test: {}%\".format(NMAE_test).ljust(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alCmALCxg68T",
        "outputId": "f8beb686-2fcd-447f-824c-142a1000c7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRMSE_train: 3.61%       NMAE_train: 2.72%        NRMSE_val: 3.22%         NMAE_val: 2.43%          NRMSE_test: 4.07%        NMAE_test: 2.91%         \n"
          ]
        }
      ]
    }
  ]
}
